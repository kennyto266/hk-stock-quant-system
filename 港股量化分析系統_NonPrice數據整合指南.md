# æ¸¯è‚¡é‡åŒ–åˆ†æç³»çµ± - éåƒ¹æ ¼æ•¸æ“šæ•´åˆæŒ‡å—

## ğŸ“Š æ¦‚è¿°

æœ¬æŒ‡å—è©³ç´°èªªæ˜å¦‚ä½•åœ¨ç¾æœ‰æ¸¯è‚¡é‡åŒ–åˆ†æç³»çµ±ä¸­æ•´åˆ**éåƒ¹æ ¼æ•¸æ“š**ï¼ˆNon-Price Dataï¼‰ï¼Œç‰¹åˆ¥æ˜¯**é¦™æ¸¯æ—¥å¤œæœŸè²¨æ•¸æ“š**ï¼Œä»¥æå‡ç­–ç•¥çš„é æ¸¬èƒ½åŠ›å’ŒAlphaç”Ÿæˆæ•ˆæœã€‚

---

## ğŸ¯ ç‚ºä»€éº¼éœ€è¦éåƒ¹æ ¼æ•¸æ“šï¼Ÿ

### å‚³çµ±åƒ¹æ ¼æ•¸æ“šçš„å±€é™æ€§
- **ä¿¡æ¯æ»¯å¾Œ**ï¼šåƒ¹æ ¼åæ˜ çš„æ˜¯å·²ç™¼ç”Ÿçš„å¸‚å ´æƒ…ç·’
- **å™ªéŸ³éå¤š**ï¼šçŸ­æœŸåƒ¹æ ¼æ³¢å‹•åŒ…å«å¤§é‡éš¨æ©Ÿæˆåˆ†
- **åŒè³ªåŒ–**ï¼šæ‰€æœ‰åƒèˆ‡è€…éƒ½çœ‹åˆ°ç›¸åŒçš„åƒ¹æ ¼æ•¸æ“š
- **æœ‰æ•ˆå¸‚å ´å‡èªª**ï¼šåƒ¹æ ¼å·²å……åˆ†åæ˜ æ‰€æœ‰å…¬é–‹ä¿¡æ¯

### éåƒ¹æ ¼æ•¸æ“šçš„å„ªå‹¢
- **ä¿¡æ¯é ˜å…ˆæ€§**ï¼šå¯èƒ½é ç¤ºæœªä¾†åƒ¹æ ¼èµ°å‹¢
- **ç¨ç‰¹æ€§**ï¼šè¼ƒå°‘äººé—œæ³¨ï¼Œç«¶çˆ­å„ªå‹¢æ˜é¡¯
- **å¤šç¶­åº¦åˆ†æ**ï¼šæä¾›æ›´å…¨é¢çš„å¸‚å ´è¦–è§’
- **é«˜å¤æ™®æ¯”ç‡æ½›åŠ›**ï¼šå‰µé€ çœŸæ­£çš„Alpha

---

## ğŸ—ï¸ ç³»çµ±æ¶æ§‹æ“´å±•

### 1. æ•¸æ“šæ¶æ§‹æ“´å±•

#### ğŸ“ æ–°å¢æ¨¡çµ„çµæ§‹
```
æ¸¯è‚¡é‡åŒ–åˆ†æç³»çµ±/
â”œâ”€â”€ ğŸ“Š non_price_data/                 # æ–°å¢ï¼šéåƒ¹æ ¼æ•¸æ“šæ¨¡çµ„
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ futures_data_handler.py        # æœŸè²¨æ•¸æ“šè™•ç†å™¨
â”‚   â”œâ”€â”€ market_sentiment_analyzer.py   # å¸‚å ´æƒ…ç·’åˆ†æå™¨
â”‚   â”œâ”€â”€ macro_data_fetcher.py          # å®è§€æ•¸æ“šç²å–å™¨
â”‚   â”œâ”€â”€ options_data_handler.py        # æœŸæ¬Šæ•¸æ“šè™•ç†å™¨
â”‚   â”œâ”€â”€ news_sentiment_analyzer.py     # æ–°èæƒ…ç·’åˆ†æå™¨
â”‚   â””â”€â”€ alternative_data_sources.py    # æ›¿ä»£æ•¸æ“šæº
â”œâ”€â”€ ğŸ”§ data_fusion/                    # æ–°å¢ï¼šæ•¸æ“šèåˆæ¨¡çµ„
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_synchronizer.py           # æ•¸æ“šåŒæ­¥å™¨
â”‚   â”œâ”€â”€ feature_engineer.py            # ç‰¹å¾µå·¥ç¨‹
â”‚   â””â”€â”€ correlation_analyzer.py        # ç›¸é—œæ€§åˆ†æå™¨
â””â”€â”€ ğŸ“ˆ enhanced_strategies/             # å¢å¼·ç­–ç•¥æ¨¡çµ„
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ multi_factor_strategies.py     # å¤šå› å­ç­–ç•¥
    â”œâ”€â”€ futures_arbitrage.py           # æœŸç¾å¥—åˆ©
    â””â”€â”€ sentiment_momentum.py          # æƒ…ç·’å‹•é‡ç­–ç•¥
```

---

## ğŸš€ Step-by-Step å¯¦æ–½è¨ˆåŠƒ

### éšæ®µ0ï¼šè‚¡ç¥¨æ•¸æ“šæ‰¹é‡ä¸‹è¼‰ç³»çµ± (1å¤©)

#### 0.1 å‰µå»ºè‚¡ç¥¨æ•¸æ“šæ‰¹é‡ä¸‹è¼‰å™¨

```python
# data_downloader/stock_data_downloader.py
import yfinance as yf
import pandas as pd
import numpy as np
from typing import List, Dict, Optional
from datetime import datetime, timedelta
import os
from pathlib import Path
from config import logger
import time

class HKStockDataDownloader:
    """æ¸¯è‚¡æ•¸æ“šæ‰¹é‡ä¸‹è¼‰å™¨"""
    
    def __init__(self, data_dir: str = "data_output/csv"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # æ¸¯è‚¡æ¨™çš„æ± 
        self.hk_stocks = {
            '2800.HK': 'ç›ˆå¯ŒåŸºé‡‘',
            '700.HK': 'é¨°è¨Šæ§è‚¡', 
            '939.HK': 'å»ºè¨­éŠ€è¡Œ',
            '941.HK': 'ä¸­åœ‹ç§»å‹•',
            '1299.HK': 'å‹é‚¦ä¿éšª',
            '1398.HK': 'å·¥å•†éŠ€è¡Œ',
            '3988.HK': 'ä¸­åœ‹éŠ€è¡Œ',
            '5.HK': 'åŒ¯è±æ§è‚¡',
            '1109.HK': 'è¯æ½¤ç½®åœ°',
            '2388.HK': 'ä¸­éŠ€é¦™æ¸¯',
            '3968.HK': 'æ‹›å•†éŠ€è¡Œ',
            '2318.HK': 'ä¸­åœ‹å¹³å®‰',
            '6862.HK': 'æµ·åº•æ’ˆ',
            '9988.HK': 'é˜¿é‡Œå·´å·´',
            '9618.HK': 'äº¬æ±é›†åœ˜',
            '3690.HK': 'ç¾åœ˜',
            '1024.HK': 'å¿«æ‰‹',
            '2269.HK': 'è—¥æ˜ç”Ÿç‰©',
            '1810.HK': 'å°ç±³é›†åœ˜',
            '9999.HK': 'ç¶²æ˜“'
        }
        
    def download_single_stock(self, 
                            symbol: str, 
                            start_date: str, 
                            end_date: str,
                            save_csv: bool = True) -> Optional[pd.DataFrame]:
        """ä¸‹è¼‰å–®éš»è‚¡ç¥¨æ•¸æ“š"""
        try:
            logger.info(f"æ­£åœ¨ä¸‹è¼‰ {symbol} ({self.hk_stocks.get(symbol, 'æœªçŸ¥')}) æ•¸æ“š...")
            
            # ä¸‹è¼‰æ•¸æ“š
            ticker = yf.Ticker(symbol)
            data = ticker.history(start=start_date, end=end_date)
            
            if data.empty:
                logger.warning(f"âŒ {symbol} æ²’æœ‰ç²å–åˆ°æ•¸æ“š")
                return None
                
            # æ•¸æ“šæ¸…ç†
            data = data.dropna()
            
            # æ·»åŠ è‚¡ç¥¨ä»£ç¢¼åˆ—
            data['Symbol'] = symbol
            data['Stock_Name'] = self.hk_stocks.get(symbol, symbol)
            
            # é‡æ–°æ’åˆ—åˆ—é †åº
            columns_order = ['Symbol', 'Stock_Name', 'Open', 'High', 'Low', 'Close', 'Volume']
            if 'Dividends' in data.columns:
                columns_order.append('Dividends')
            if 'Stock Splits' in data.columns:
                columns_order.append('Stock Splits')
                
            data = data[columns_order]
            
            if save_csv:
                # ä¿å­˜åˆ°CSV
                filename = f"{symbol.replace('.', '_')}_stock_data.csv"
                filepath = self.data_dir / filename
                data.to_csv(filepath)
                logger.info(f"âœ… {symbol} æ•¸æ“šå·²ä¿å­˜åˆ° {filepath}")
                
            return data
            
        except Exception as e:
            logger.error(f"âŒ ä¸‹è¼‰ {symbol} æ•¸æ“šå¤±æ•—: {e}")
            return None
            
    def download_all_stocks(self, 
                          start_date: str = "2023-01-01", 
                          end_date: str = None,
                          delay_seconds: float = 1.0) -> Dict[str, pd.DataFrame]:
        """æ‰¹é‡ä¸‹è¼‰æ‰€æœ‰è‚¡ç¥¨æ•¸æ“š"""
        if end_date is None:
            end_date = datetime.now().strftime('%Y-%m-%d')
            
        logger.info(f"é–‹å§‹æ‰¹é‡ä¸‹è¼‰ {len(self.hk_stocks)} éš»æ¸¯è‚¡æ•¸æ“š...")
        logger.info(f"æ™‚é–“ç¯„åœ: {start_date} åˆ° {end_date}")
        
        all_data = {}
        failed_downloads = []
        
        for i, (symbol, name) in enumerate(self.hk_stocks.items(), 1):
            logger.info(f"é€²åº¦: {i}/{len(self.hk_stocks)} - {symbol}")
            
            data = self.download_single_stock(symbol, start_date, end_date)
            
            if data is not None:
                all_data[symbol] = data
            else:
                failed_downloads.append(symbol)
                
            # æ·»åŠ å»¶é²é¿å…è¢«é™åˆ¶
            if delay_seconds > 0:
                time.sleep(delay_seconds)
                
        # ç”Ÿæˆæ‘˜è¦å ±å‘Š
        self._generate_download_report(all_data, failed_downloads)
        
        return all_data
    
    def create_combined_dataset(self, 
                              all_data: Dict[str, pd.DataFrame],
                              save_csv: bool = True) -> pd.DataFrame:
        """å‰µå»ºåˆä½µæ•¸æ“šé›†"""
        try:
            # åˆä½µæ‰€æœ‰è‚¡ç¥¨æ•¸æ“š
            combined_data = pd.concat(all_data.values(), ignore_index=False)
            combined_data = combined_data.sort_index()
            
            if save_csv:
                # ä¿å­˜åˆä½µæ•¸æ“š
                filename = f"HK_Stocks_Combined_{datetime.now().strftime('%Y%m%d')}.csv"
                filepath = self.data_dir / filename
                combined_data.to_csv(filepath)
                logger.info(f"âœ… åˆä½µæ•¸æ“šå·²ä¿å­˜åˆ° {filepath}")
                
            return combined_data
            
        except Exception as e:
            logger.error(f"âŒ å‰µå»ºåˆä½µæ•¸æ“šé›†å¤±æ•—: {e}")
            return pd.DataFrame()
    
    def _generate_download_report(self, 
                                successful_data: Dict[str, pd.DataFrame],
                                failed_downloads: List[str]):
        """ç”Ÿæˆä¸‹è¼‰å ±å‘Š"""
        report_lines = [
            "=" * 50,
            "æ¸¯è‚¡æ•¸æ“šä¸‹è¼‰å ±å‘Š",
            "=" * 50,
            f"ç¸½å…±å˜—è©¦ä¸‹è¼‰: {len(self.hk_stocks)} éš»è‚¡ç¥¨",
            f"æˆåŠŸä¸‹è¼‰: {len(successful_data)} éš»è‚¡ç¥¨",
            f"ä¸‹è¼‰å¤±æ•—: {len(failed_downloads)} éš»è‚¡ç¥¨",
            ""
        ]
        
        if successful_data:
            report_lines.append("æˆåŠŸä¸‹è¼‰çš„è‚¡ç¥¨:")
            for symbol in successful_data.keys():
                data_points = len(successful_data[symbol])
                start_date = successful_data[symbol].index.min().strftime('%Y-%m-%d')
                end_date = successful_data[symbol].index.max().strftime('%Y-%m-%d')
                report_lines.append(f"  {symbol}: {data_points} å€‹äº¤æ˜“æ—¥ ({start_date} è‡³ {end_date})")
                
        if failed_downloads:
            report_lines.append("\nä¸‹è¼‰å¤±æ•—çš„è‚¡ç¥¨:")
            for symbol in failed_downloads:
                report_lines.append(f"  {symbol}")
                
        report_content = "\n".join(report_lines)
        
        # ä¿å­˜å ±å‘Š
        report_filename = f"download_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        report_filepath = self.data_dir.parent / "reports" / report_filename
        report_filepath.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_filepath, 'w', encoding='utf-8') as f:
            f.write(report_content)
            
        # åŒæ™‚è¼¸å‡ºåˆ°æ§åˆ¶å°
        logger.info(f"\n{report_content}")
        logger.info(f"è©³ç´°å ±å‘Šå·²ä¿å­˜åˆ°: {report_filepath}")

    def update_existing_data(self, 
                           symbols: List[str] = None,
                           days_back: int = 7) -> Dict[str, pd.DataFrame]:
        """æ›´æ–°ç¾æœ‰æ•¸æ“šï¼ˆå¢é‡ä¸‹è¼‰ï¼‰"""
        if symbols is None:
            symbols = list(self.hk_stocks.keys())
            
        end_date = datetime.now().strftime('%Y-%m-%d')
        start_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')
        
        logger.info(f"å¢é‡æ›´æ–°æœ€è¿‘ {days_back} å¤©çš„æ•¸æ“š...")
        
        updated_data = {}
        for symbol in symbols:
            # æª¢æŸ¥ç¾æœ‰æ–‡ä»¶
            filename = f"{symbol.replace('.', '_')}_stock_data.csv"
            filepath = self.data_dir / filename
            
            if filepath.exists():
                # è®€å–ç¾æœ‰æ•¸æ“š
                existing_data = pd.read_csv(filepath, index_col=0, parse_dates=True)
                
                # ä¸‹è¼‰æ–°æ•¸æ“š
                new_data = self.download_single_stock(symbol, start_date, end_date, save_csv=False)
                
                if new_data is not None:
                    # åˆä½µæ•¸æ“šï¼ˆå»é‡ï¼‰
                    combined = pd.concat([existing_data, new_data])
                    combined = combined[~combined.index.duplicated(keep='last')]
                    combined = combined.sort_index()
                    
                    # ä¿å­˜æ›´æ–°å¾Œçš„æ•¸æ“š
                    combined.to_csv(filepath)
                    updated_data[symbol] = combined
                    logger.info(f"âœ… {symbol} æ•¸æ“šå·²æ›´æ–°")
            else:
                # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå®Œæ•´ä¸‹è¼‰
                data = self.download_single_stock(symbol, "2023-01-01", end_date)
                if data is not None:
                    updated_data[symbol] = data
                    
        return updated_data
```

#### 0.2 å‰µå»ºæ•¸æ“šä¸‹è¼‰è…³æœ¬

```python
# scripts/download_hk_stocks.py
"""
æ¸¯è‚¡æ•¸æ“šæ‰¹é‡ä¸‹è¼‰è…³æœ¬
ä½¿ç”¨æ–¹æ³•: python scripts/download_hk_stocks.py
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from data_downloader.stock_data_downloader import HKStockDataDownloader
from config import logger
import argparse
from datetime import datetime, timedelta

def main():
    parser = argparse.ArgumentParser(description='æ¸¯è‚¡æ•¸æ“šæ‰¹é‡ä¸‹è¼‰å·¥å…·')
    parser.add_argument('--start-date', type=str, 
                       default=(datetime.now() - timedelta(days=730)).strftime('%Y-%m-%d'),
                       help='é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--end-date', type=str, 
                       default=datetime.now().strftime('%Y-%m-%d'),
                       help='çµæŸæ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--symbols', nargs='+', 
                       help='æŒ‡å®šè‚¡ç¥¨ä»£ç¢¼ï¼ˆå¯é¸ï¼‰')
    parser.add_argument('--update-only', action='store_true',
                       help='åƒ…æ›´æ–°ç¾æœ‰æ•¸æ“š')
    parser.add_argument('--delay', type=float, default=1.0,
                       help='ä¸‹è¼‰é–“éš”ï¼ˆç§’ï¼‰')
    
    args = parser.parse_args()
    
    # å‰µå»ºä¸‹è¼‰å™¨
    downloader = HKStockDataDownloader()
    
    if args.update_only:
        # å¢é‡æ›´æ–°æ¨¡å¼
        logger.info("ğŸ”„ åŸ·è¡Œå¢é‡æ›´æ–°...")
        updated_data = downloader.update_existing_data(
            symbols=args.symbols,
            days_back=7
        )
        logger.info(f"âœ… å®Œæˆï¼æ›´æ–°äº† {len(updated_data)} éš»è‚¡ç¥¨")
        
    else:
        # å®Œæ•´ä¸‹è¼‰æ¨¡å¼
        if args.symbols:
            # ä¸‹è¼‰æŒ‡å®šè‚¡ç¥¨
            downloader.hk_stocks = {
                symbol: downloader.hk_stocks.get(symbol, symbol) 
                for symbol in args.symbols
            }
            
        logger.info("ğŸ“¥ åŸ·è¡Œå®Œæ•´æ•¸æ“šä¸‹è¼‰...")
        all_data = downloader.download_all_stocks(
            start_date=args.start_date,
            end_date=args.end_date,
            delay_seconds=args.delay
        )
        
        if all_data:
            # å‰µå»ºåˆä½µæ•¸æ“šé›†
            combined_data = downloader.create_combined_dataset(all_data)
            logger.info(f"âœ… å®Œæˆï¼ä¸‹è¼‰äº† {len(all_data)} éš»è‚¡ç¥¨ï¼Œå…± {len(combined_data)} æ¢è¨˜éŒ„")
        else:
            logger.error("âŒ æ²’æœ‰æˆåŠŸä¸‹è¼‰ä»»ä½•æ•¸æ“š")

if __name__ == "__main__":
    main()
```

### éšæ®µ1ï¼šé¦™æ¸¯æ—¥å¤œæœŸè²¨æ•¸æ“šæ•´åˆ (2-3å¤©)

#### 1.1 å‰µå»ºæœŸè²¨æ•¸æ“šè™•ç†å™¨

```python
# non_price_data/futures_data_handler.py
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple
import yfinance as yf
import requests
from datetime import datetime, timedelta
from config import logger

class HKFuturesDataHandler:
    \"\"\"é¦™æ¸¯æœŸè²¨æ•¸æ“šè™•ç†å™¨\"\"\"
    
    def __init__(self):
        self.futures_symbols = {
            'HSI_DAY': '^HSI',      # æ†æŒ‡æ—¥é–“æœŸè²¨
            'HSI_NIGHT': 'HSI2300', # æ†æŒ‡å¤œé–“æœŸè²¨
            'HSCEI': '^HSCE',       # åœ‹ä¼æŒ‡æ•¸æœŸè²¨
            'HSTECH': '^HSTECH'     # æ†ç”Ÿç§‘æŠ€æŒ‡æ•¸æœŸè²¨
        }
        
    def fetch_futures_data(self, 
                          start_date: str, 
                          end_date: str,
                          symbols: List[str] = None) -> Dict[str, pd.DataFrame]:
        \"\"\"ç²å–æœŸè²¨æ•¸æ“š\"\"\"
        if symbols is None:
            symbols = list(self.futures_symbols.keys())
            
        futures_data = {}
        
        for symbol in symbols:
            try:
                ticker = self.futures_symbols.get(symbol)
                if ticker:
                    data = yf.download(ticker, start=start_date, end=end_date)
                    futures_data[symbol] = data
                    logger.info(f\"âœ… æˆåŠŸç²å– {symbol} æœŸè²¨æ•¸æ“š\")
            except Exception as e:
                logger.error(f\"âŒ ç²å– {symbol} æœŸè²¨æ•¸æ“šå¤±æ•—: {e}\")
                
        return futures_data
    
    def calculate_day_night_spread(self, 
                                  day_data: pd.DataFrame, 
                                  night_data: pd.DataFrame) -> pd.DataFrame:
        \"\"\"è¨ˆç®—æ—¥å¤œæœŸè²¨åƒ¹å·®\"\"\"
        try:
            # å°é½Šæ•¸æ“šæ™‚é–“æˆ³
            aligned_data = pd.merge(
                day_data[['Close']].rename(columns={'Close': 'Day_Close'}),
                night_data[['Close']].rename(columns={'Close': 'Night_Close'}),
                left_index=True, right_index=True, how='inner'
            )
            
            # è¨ˆç®—åƒ¹å·®æŒ‡æ¨™
            aligned_data['Spread'] = aligned_data['Night_Close'] - aligned_data['Day_Close']
            aligned_data['Spread_Pct'] = aligned_data['Spread'] / aligned_data['Day_Close'] * 100
            aligned_data['Spread_MA5'] = aligned_data['Spread_Pct'].rolling(5).mean()
            aligned_data['Spread_Std5'] = aligned_data['Spread_Pct'].rolling(5).std()
            aligned_data['Spread_Zscore'] = (aligned_data['Spread_Pct'] - aligned_data['Spread_MA5']) / aligned_data['Spread_Std5']
            
            return aligned_data
            
        except Exception as e:
            logger.error(f\"è¨ˆç®—æ—¥å¤œåƒ¹å·®å¤±æ•—: {e}\")
            return pd.DataFrame()
    
    def generate_futures_signals(self, spread_data: pd.DataFrame) -> pd.DataFrame:
        \"\"\"åŸºæ–¼æœŸè²¨åƒ¹å·®ç”Ÿæˆäº¤æ˜“ä¿¡è™Ÿ\"\"\"
        signals = pd.DataFrame(index=spread_data.index)
        
        # ä¿¡è™Ÿ1ï¼šåƒ¹å·®å‡å€¼å›æ­¸
        signals['Mean_Reversion_Signal'] = np.where(
            spread_data['Spread_Zscore'] > 2, -1,  # åšç©ºä¿¡è™Ÿ
            np.where(spread_data['Spread_Zscore'] < -2, 1, 0)  # åšå¤šä¿¡è™Ÿ
        )
        
        # ä¿¡è™Ÿ2ï¼šè¶¨å‹¢è·Ÿéš¨
        signals['Trend_Signal'] = np.where(
            spread_data['Spread_Pct'] > spread_data['Spread_MA5'], 1, -1
        )
        
        # ä¿¡è™Ÿ3ï¼šæ³¢å‹•ç‡çªç ´
        signals['Volatility_Signal'] = np.where(
            abs(spread_data['Spread_Zscore']) > 1.5, 1, 0
        )
        
        return signals
```

#### 1.2 ä¿®æ”¹ç¾æœ‰é…ç½®æ–‡ä»¶

```python
# config.py æ–°å¢é…ç½®
@dataclass
class NonPriceDataConfig:
    \"\"\"éåƒ¹æ ¼æ•¸æ“šé…ç½®\"\"\"
    # æœŸè²¨æ•¸æ“šé…ç½®
    enable_futures_data: bool = True
    futures_update_interval: int = 300  # 5åˆ†é˜æ›´æ–°
    futures_lookback_days: int = 30     # æœŸè²¨æ•¸æ“šå›çœ‹å¤©æ•¸
    
    # å¸‚å ´æƒ…ç·’é…ç½®
    enable_sentiment_analysis: bool = True
    sentiment_sources: List[str] = ['news', 'social_media', 'options']
    
    # å®è§€æ•¸æ“šé…ç½®
    enable_macro_data: bool = True
    macro_indicators: List[str] = ['interest_rate', 'exchange_rate', 'vix']
    
    # æ•¸æ“šèåˆé…ç½®
    correlation_threshold: float = 0.3
    feature_selection_method: str = 'mutual_info'
    max_features: int = 50

# æ·»åŠ åˆ°å…¨åŸŸé…ç½®
NON_PRICE_CONFIG = NonPriceDataConfig()
```

#### 1.3 æ“´å±•æ•¸æ“šè™•ç†ä¸»é¡

```python
# data_handler.py æ–°å¢æ–¹æ³•
class DataFetcher:
    # ... ç¾æœ‰ä»£ç¢¼ ...
    
    @staticmethod
    def get_non_price_data(symbol: str, 
                          start_date: str, 
                          end_date: str,
                          data_types: List[str] = ['futures']) -> Dict[str, pd.DataFrame]:
        \"\"\"ç²å–éåƒ¹æ ¼æ•¸æ“š\"\"\"
        non_price_data = {}
        
        if 'futures' in data_types:
            from non_price_data.futures_data_handler import HKFuturesDataHandler
            futures_handler = HKFuturesDataHandler()
            futures_data = futures_handler.fetch_futures_data(start_date, end_date)
            non_price_data['futures'] = futures_data
            
        if 'sentiment' in data_types:
            # å¯¦ç¾æƒ…ç·’æ•¸æ“šç²å–
            pass
            
        if 'macro' in data_types:
            # å¯¦ç¾å®è§€æ•¸æ“šç²å–
            pass
            
        return non_price_data
```

### éšæ®µ2ï¼šæ•¸æ“šèåˆå’Œç‰¹å¾µå·¥ç¨‹ (2-3å¤©)

#### 2.1 å‰µå»ºæ•¸æ“šåŒæ­¥å™¨

```python
# data_fusion/data_synchronizer.py
class DataSynchronizer:
    \"\"\"å¤šæºæ•¸æ“šåŒæ­¥å™¨\"\"\"
    
    def __init__(self):
        self.time_tolerance = timedelta(minutes=30)  # æ™‚é–“å®¹å·®
        
    def synchronize_datasets(self, 
                           price_data: pd.DataFrame,
                           non_price_data: Dict[str, pd.DataFrame]) -> pd.DataFrame:
        \"\"\"åŒæ­¥åƒ¹æ ¼å’Œéåƒ¹æ ¼æ•¸æ“š\"\"\"
        # ä»¥åƒ¹æ ¼æ•¸æ“šçš„æ™‚é–“æˆ³ç‚ºåŸºæº–
        base_index = price_data.index
        synchronized_data = price_data.copy()
        
        for data_type, data in non_price_data.items():
            # æ™‚é–“å°é½Š
            aligned_data = self._align_timestamps(base_index, data)
            
            # æ·»åŠ å‰ç¶´é¿å…åˆ—åè¡çª
            aligned_data.columns = [f\"{data_type}_{col}\" for col in aligned_data.columns]
            
            # åˆä½µæ•¸æ“š
            synchronized_data = pd.merge(
                synchronized_data, aligned_data,
                left_index=True, right_index=True,
                how='left'
            )
            
        return synchronized_data
    
    def _align_timestamps(self, 
                         target_index: pd.DatetimeIndex, 
                         source_data: pd.DataFrame) -> pd.DataFrame:
        \"\"\"å°é½Šæ™‚é–“æˆ³\"\"\"
        # ä½¿ç”¨å‰å‘å¡«å……å’Œç·šæ€§æ’å€¼
        aligned = source_data.reindex(target_index, method='ffill')
        aligned = aligned.interpolate(method='linear', limit=5)
        return aligned
```

#### 2.2 å‰µå»ºç‰¹å¾µå·¥ç¨‹æ¨¡çµ„

```python
# data_fusion/feature_engineer.py
class FeatureEngineer:
    \"\"\"ç‰¹å¾µå·¥ç¨‹å™¨\"\"\"
    
    def __init__(self):
        self.feature_cache = {}
        
    def create_futures_features(self, 
                               price_data: pd.DataFrame,
                               futures_data: Dict[str, pd.DataFrame]) -> pd.DataFrame:
        \"\"\"å‰µå»ºæœŸè²¨ç›¸é—œç‰¹å¾µ\"\"\"
        features = pd.DataFrame(index=price_data.index)
        
        # ç‰¹å¾µ1ï¼šæœŸç¾åŸºå·®
        if 'HSI_DAY' in futures_data:
            hsi_futures = futures_data['HSI_DAY']
            features['Basis'] = hsi_futures['Close'] - price_data['Close']
            features['Basis_Pct'] = features['Basis'] / price_data['Close'] * 100
            
        # ç‰¹å¾µ2ï¼šæ—¥å¤œåƒ¹å·®
        if 'HSI_DAY' in futures_data and 'HSI_NIGHT' in futures_data:
            day_night_spread = self._calculate_day_night_spread(
                futures_data['HSI_DAY'], futures_data['HSI_NIGHT']
            )
            features = pd.merge(features, day_night_spread, 
                              left_index=True, right_index=True, how='left')
            
        # ç‰¹å¾µ3ï¼šæœŸè²¨æˆäº¤é‡æ¯”ç‡
        features['Futures_Volume_Ratio'] = (
            hsi_futures['Volume'] / price_data['Volume']
        ).rolling(5).mean()
        
        # ç‰¹å¾µ4ï¼šæœŸè²¨æ³¢å‹•ç‡
        features['Futures_Volatility'] = (
            hsi_futures['Close'].pct_change().rolling(20).std() * np.sqrt(252)
        )
        
        return features
    
    def create_technical_features(self, data: pd.DataFrame) -> pd.DataFrame:
        \"\"\"å‰µå»ºæŠ€è¡“æŒ‡æ¨™ç‰¹å¾µ\"\"\"
        features = pd.DataFrame(index=data.index)
        
        # åƒ¹æ ¼å‹•é‡ç‰¹å¾µ
        for period in [5, 10, 20]:
            features[f'Momentum_{period}'] = data['Close'].pct_change(period)
            features[f'Price_MA_Ratio_{period}'] = data['Close'] / data['Close'].rolling(period).mean()
            
        # æ³¢å‹•ç‡ç‰¹å¾µ
        for period in [5, 10, 20]:
            features[f'Volatility_{period}'] = data['Close'].pct_change().rolling(period).std()
            
        # æˆäº¤é‡ç‰¹å¾µ
        features['Volume_MA_Ratio'] = data['Volume'] / data['Volume'].rolling(20).mean()
        features['Price_Volume_Trend'] = (data['Close'].pct_change() * data['Volume']).rolling(5).mean()
        
        return features
    
    def select_features(self, 
                       features: pd.DataFrame, 
                       target: pd.Series,
                       method: str = 'mutual_info',
                       max_features: int = 50) -> List[str]:
        \"\"\"ç‰¹å¾µé¸æ“‡\"\"\"
        from sklearn.feature_selection import mutual_info_regression, SelectKBest
        from sklearn.feature_selection import f_regression
        
        # ç§»é™¤NaNå€¼
        clean_features = features.dropna()
        clean_target = target.loc[clean_features.index]
        
        if method == 'mutual_info':
            selector = SelectKBest(
                score_func=mutual_info_regression, 
                k=min(max_features, clean_features.shape[1])
            )
        else:
            selector = SelectKBest(
                score_func=f_regression,
                k=min(max_features, clean_features.shape[1])
            )
            
        selector.fit(clean_features, clean_target)
        selected_features = clean_features.columns[selector.get_support()].tolist()
        
        return selected_features
```

### éšæ®µ3ï¼šå¢å¼·ç­–ç•¥é–‹ç™¼ (3-4å¤©)

#### 3.1 å¤šå› å­ç­–ç•¥

```python
# enhanced_strategies/multi_factor_strategies.py
class MultiFactorStrategy:
    """å¤šå› å­ç­–ç•¥åŸºé¡"""
    
    def __init__(self, factors: List[str], weights: Dict[str, float] = None):
        self.factors = factors
        self.weights = weights or {factor: 1.0/len(factors) for factor in factors}
        self.factor_scores = {}
        
    def calculate_factor_scores(self, data: pd.DataFrame) -> pd.DataFrame:
        """è¨ˆç®—å„å› å­å¾—åˆ†"""
        scores = pd.DataFrame(index=data.index)
        
        # æœŸè²¨åŸºå·®å› å­
        if 'futures_basis' in self.factors:
            scores['futures_basis'] = self._normalize_factor(
                data.get('Basis_Pct', pd.Series(index=data.index))
            )
            
        # æ—¥å¤œåƒ¹å·®å› å­
        if 'day_night_spread' in self.factors:
            scores['day_night_spread'] = self._normalize_factor(
                data.get('Spread_Zscore', pd.Series(index=data.index))
            )
            
        # å‹•é‡å› å­
        if 'momentum' in self.factors:
            scores['momentum'] = self._normalize_factor(
                data['Close'].pct_change(20)
            )
            
        # æ³¢å‹•ç‡å› å­
        if 'volatility' in self.factors:
            vol = data['Close'].pct_change().rolling(20).std()
            scores['volatility'] = self._normalize_factor(-vol)  # ä½æ³¢å‹•ç‡ç‚ºæ­£
            
        return scores
    
    def _normalize_factor(self, factor_data: pd.Series) -> pd.Series:
        """æ¨™æº–åŒ–å› å­æ•¸æ“š"""
        return (factor_data - factor_data.rolling(252).mean()) / factor_data.rolling(252).std()
    
    def generate_signals(self, factor_scores: pd.DataFrame) -> pd.Series:
        """åŸºæ–¼å› å­å¾—åˆ†ç”Ÿæˆä¿¡è™Ÿ"""
        composite_score = pd.Series(0, index=factor_scores.index)
        
        for factor, weight in self.weights.items():
            if factor in factor_scores.columns:
                composite_score += weight * factor_scores[factor]
                
        # ç”Ÿæˆä¸‰åˆ†ä½ä¿¡è™Ÿ
        signals = pd.Series(0, index=composite_score.index)
        
        # æ»¾å‹•æ’å
        rolling_rank = composite_score.rolling(60).rank(pct=True)
        
        signals[rolling_rank > 0.7] = 1   # åšå¤šä¿¡è™Ÿ
        signals[rolling_rank < 0.3] = -1  # åšç©ºä¿¡è™Ÿ
        
        return signals
```

#### 3.2 æœŸç¾å¥—åˆ©ç­–ç•¥

```python
# enhanced_strategies/futures_arbitrage.py
class FuturesArbitrageStrategy:
    """æœŸç¾å¥—åˆ©ç­–ç•¥"""
    
    def __init__(self, spread_threshold: float = 2.0):
        self.spread_threshold = spread_threshold
        
    def generate_arbitrage_signals(self, 
                                 spot_data: pd.DataFrame,
                                 futures_data: pd.DataFrame) -> pd.DataFrame:
        """ç”Ÿæˆå¥—åˆ©ä¿¡è™Ÿ"""
        signals = pd.DataFrame(index=spot_data.index)
        
        # è¨ˆç®—åŸºå·®
        basis = futures_data['Close'] - spot_data['Close']
        basis_zscore = (basis - basis.rolling(60).mean()) / basis.rolling(60).std()
        
        # å¥—åˆ©ä¿¡è™Ÿ
        signals['Long_Spot_Short_Futures'] = np.where(basis_zscore > self.spread_threshold, 1, 0)
        signals['Short_Spot_Long_Futures'] = np.where(basis_zscore < -self.spread_threshold, 1, 0)
        
        # å¹³å€‰ä¿¡è™Ÿ
        signals['Close_Position'] = np.where(abs(basis_zscore) < 0.5, 1, 0)
        
        return signals
```

### éšæ®µ4ï¼šç³»çµ±æ•´åˆå’Œå„€è¡¨æ¿æ“´å±• (2-3å¤©)

#### 4.1 ä¿®æ”¹ä¸»å„€è¡¨æ¿ä»¥æ”¯æ´éåƒ¹æ ¼æ•¸æ“š

```python
# enhanced_interactive_dashboard.py æ–°å¢åŠŸèƒ½
def load_non_price_data():
    """è¼‰å…¥éåƒ¹æ ¼æ•¸æ“š"""
    try:
        from non_price_data.futures_data_handler import HKFuturesDataHandler
        from data_fusion.data_synchronizer import DataSynchronizer
        from data_fusion.feature_engineer import FeatureEngineer
        
        # è¼‰å…¥æœŸè²¨æ•¸æ“š
        futures_handler = HKFuturesDataHandler()
        futures_data = futures_handler.fetch_futures_data(
            start_date="2024-01-01", 
            end_date="2024-12-31"
        )
        
        # è¼‰å…¥è‚¡ç¥¨æ•¸æ“š
        stock_data = load_stock_data_from_csv()
        
        # æ•¸æ“šåŒæ­¥
        synchronizer = DataSynchronizer()
        synchronized_data = synchronizer.synchronize_datasets(
            stock_data, {'futures': futures_data}
        )
        
        # ç‰¹å¾µå·¥ç¨‹
        feature_engineer = FeatureEngineer()
        features = feature_engineer.create_futures_features(stock_data, futures_data)
        
        return synchronized_data, features
        
    except Exception as e:
        logger.error(f"è¼‰å…¥éåƒ¹æ ¼æ•¸æ“šå¤±æ•—: {e}")
        return None, None

def create_non_price_charts(features: pd.DataFrame):
    """å‰µå»ºéåƒ¹æ ¼æ•¸æ“šåœ–è¡¨"""
    charts = []
    
    # æœŸç¾åŸºå·®åœ–
    if 'Basis_Pct' in features.columns:
        basis_chart = go.Scatter(
            x=features.index,
            y=features['Basis_Pct'],
            mode='lines',
            name='æœŸç¾åŸºå·® (%)',
            line=dict(color='orange')
        )
        charts.append(basis_chart)
    
    # æ—¥å¤œåƒ¹å·®åœ–
    if 'Spread_Zscore' in features.columns:
        spread_chart = go.Scatter(
            x=features.index,
            y=features['Spread_Zscore'],
            mode='lines',
            name='æ—¥å¤œåƒ¹å·® Z-Score',
            line=dict(color='purple')
        )
        charts.append(spread_chart)
    
    return charts

# åœ¨ä¸»å„€è¡¨æ¿å›èª¿ä¸­æ·»åŠ éåƒ¹æ ¼æ•¸æ“š
@app.callback(
    Output('main-chart', 'figure'),
    [Input('strategy-checkboxes', 'value'),
     Input('show-non-price', 'value')]  # æ–°å¢æ§åˆ¶é …
)
def update_main_chart(selected_strategies, show_non_price):
    """æ›´æ–°ä¸»åœ–è¡¨ï¼ŒåŒ…å«éåƒ¹æ ¼æ•¸æ“š"""
    # ... ç¾æœ‰ç­–ç•¥é‚è¼¯ ...
    
    if show_non_price and 'non_price_features' in globals():
        non_price_charts = create_non_price_charts(non_price_features)
        for chart in non_price_charts:
            main_fig.add_trace(chart)
    
    return main_fig
```

#### 4.2 æ·»åŠ æ–°çš„æ§åˆ¶é¢æ¿

```python
# åœ¨å„€è¡¨æ¿ä½ˆå±€ä¸­æ·»åŠ éåƒ¹æ ¼æ•¸æ“šæ§åˆ¶
html.Div([
    html.H5("éåƒ¹æ ¼æ•¸æ“šé¸é …", style={'color': '#eee', 'marginBottom': '10px'}),
    dcc.Checklist(
        id='non-price-options',
        options=[
            {'label': 'æœŸç¾åŸºå·®', 'value': 'basis'},
            {'label': 'æ—¥å¤œåƒ¹å·®', 'value': 'day_night_spread'},
            {'label': 'æœŸè²¨æ³¢å‹•ç‡', 'value': 'futures_volatility'},
            {'label': 'æˆäº¤é‡æ¯”ç‡', 'value': 'volume_ratio'}
        ],
        value=[],
        style={'color': '#eee'}
    )
], style={'marginBottom': '20px'})
```

### éšæ®µ5ï¼šæ¸¬è©¦å’Œé©—è­‰ (1-2å¤©)

#### 5.1 æ•¸æ“šè³ªé‡æª¢æŸ¥

```python
# tests/test_non_price_data.py
def test_futures_data_quality():
    """æ¸¬è©¦æœŸè²¨æ•¸æ“šè³ªé‡"""
    from non_price_data.futures_data_handler import HKFuturesDataHandler
    
    handler = HKFuturesDataHandler()
    data = handler.fetch_futures_data("2024-01-01", "2024-12-31")
    
    assert len(data) > 0, "æœŸè²¨æ•¸æ“šç‚ºç©º"
    assert 'HSI_DAY' in data, "ç¼ºå°‘æ†æŒ‡æ—¥é–“æ•¸æ“š"
    assert not data['HSI_DAY'].empty, "æ†æŒ‡æ—¥é–“æ•¸æ“šç‚ºç©º"
    
    # æª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§
    assert data['HSI_DAY']['Close'].notna().sum() > 200, "æœ‰æ•ˆæ•¸æ“šé»å¤ªå°‘"
    
def test_feature_engineering():
    """æ¸¬è©¦ç‰¹å¾µå·¥ç¨‹"""
    from data_fusion.feature_engineer import FeatureEngineer
    
    # æ¨¡æ“¬æ•¸æ“š
    price_data = pd.DataFrame({
        'Close': np.random.randn(100).cumsum() + 100,
        'Volume': np.random.randint(1000, 10000, 100)
    }, index=pd.date_range('2024-01-01', periods=100))
    
    futures_data = {
        'HSI_DAY': pd.DataFrame({
            'Close': np.random.randn(100).cumsum() + 105,
            'Volume': np.random.randint(1000, 10000, 100)
        }, index=pd.date_range('2024-01-01', periods=100))
    }
    
    engineer = FeatureEngineer()
    features = engineer.create_futures_features(price_data, futures_data)
    
    assert 'Basis' in features.columns, "ç¼ºå°‘åŸºå·®ç‰¹å¾µ"
    assert features['Basis'].notna().sum() > 50, "åŸºå·®ç‰¹å¾µæœ‰å¤ªå¤šNaN"
```

#### 5.2 ç­–ç•¥å›æ¸¬é©—è­‰

```python
def backtest_multi_factor_strategy():
    """å›æ¸¬å¤šå› å­ç­–ç•¥"""
    from enhanced_strategies.multi_factor_strategies import MultiFactorStrategy
    
    # è¼‰å…¥æ•¸æ“š
    synchronized_data, features = load_non_price_data()
    
    # å‰µå»ºç­–ç•¥
    strategy = MultiFactorStrategy(
        factors=['futures_basis', 'momentum', 'volatility'],
        weights={'futures_basis': 0.4, 'momentum': 0.4, 'volatility': 0.2}
    )
    
    # è¨ˆç®—å› å­å¾—åˆ†
    factor_scores = strategy.calculate_factor_scores(features)
    
    # ç”Ÿæˆä¿¡è™Ÿ
    signals = strategy.generate_signals(factor_scores)
    
    # è¨ˆç®—å›æ¸¬è¡¨ç¾
    returns = synchronized_data['Close'].pct_change() * signals.shift(1)
    
    # è©•ä¼°æŒ‡æ¨™
    annual_return = returns.mean() * 252
    volatility = returns.std() * np.sqrt(252)
    sharpe_ratio = annual_return / volatility if volatility > 0 else 0
    
    print(f"å¤šå› å­ç­–ç•¥è¡¨ç¾:")
    print(f"å¹´åŒ–æ”¶ç›Šç‡: {annual_return:.2%}")
    print(f"å¹´åŒ–æ³¢å‹•ç‡: {volatility:.2%}")
    print(f"å¤æ™®æ¯”ç‡: {sharpe_ratio:.2f}")
    
    return {
        'annual_return': annual_return,
        'volatility': volatility,
        'sharpe_ratio': sharpe_ratio
    }
```

---

## ğŸ¯ å…·é«”å¯¦æ–½æ­¥é©Ÿ

### ç¬¬1é€±ï¼šåŸºç¤å»ºè¨­

**Day 1-2: ç’°å¢ƒæº–å‚™**
```bash
# å®‰è£æ–°ä¾è³´
pip install scikit-learn
pip install pandas-ta
pip install yfinance>=0.2.0

# å‰µå»ºæ–°ç›®éŒ„çµæ§‹
mkdir non_price_data
mkdir data_fusion 
mkdir enhanced_strategies
mkdir tests
```

**Day 3-4: æœŸè²¨æ•¸æ“šæ¨¡çµ„**
- å¯¦æ–½ `HKFuturesDataHandler` é¡
- æ¸¬è©¦æœŸè²¨æ•¸æ“šç²å–åŠŸèƒ½
- é©—è­‰æ—¥å¤œåƒ¹å·®è¨ˆç®—

**Day 5-7: æ•¸æ“šèåˆæ¡†æ¶**
- å¯¦æ–½ `DataSynchronizer` é¡
- å¯¦æ–½ `FeatureEngineer` é¡
- å»ºç«‹ç‰¹å¾µé¸æ“‡ç®¡é“

### ç¬¬2é€±ï¼šç­–ç•¥é–‹ç™¼

**Day 8-10: å¤šå› å­ç­–ç•¥**
- å¯¦æ–½åŸºç¤å¤šå› å­æ¡†æ¶
- é–‹ç™¼æœŸè²¨åŸºå·®å› å­
- é–‹ç™¼å‹•é‡å’Œæ³¢å‹•ç‡å› å­

**Day 11-12: æœŸç¾å¥—åˆ©ç­–ç•¥**
- å¯¦æ–½å¥—åˆ©ä¿¡è™Ÿç”Ÿæˆé‚è¼¯
- å»ºç«‹é¢¨éšªæ§åˆ¶æ©Ÿåˆ¶
- å›æ¸¬é©—è­‰ç­–ç•¥æ•ˆæœ

**Day 13-14: ç³»çµ±æ•´åˆ**
- æ•´åˆæ‰€æœ‰æ–°æ¨¡çµ„
- æ›´æ–°ä¸»å„€è¡¨æ¿
- æ·»åŠ æ–°çš„å¯è¦–åŒ–åŠŸèƒ½

---

## ğŸ“Š æ•ˆæœè©•ä¼°æŒ‡æ¨™

### ç­–ç•¥è¡¨ç¾æŒ‡æ¨™
- **å¤æ™®æ¯”ç‡**ï¼šç›®æ¨™ > 2.0ï¼ˆç›¸æ¯”ç´”åƒ¹æ ¼ç­–ç•¥çš„1.5ï¼‰
- **è³‡è¨Šæ¯”ç‡**ï¼šè¡¡é‡ç›¸å°åŸºæº–çš„è¶…é¡æ”¶ç›Šç©©å®šæ€§
- **æœ€å¤§å›æ’¤**ï¼šæ§åˆ¶åœ¨ < 5%
- **å‹ç‡**ï¼šç›®æ¨™ > 55%

### æ•¸æ“šè³ªé‡æŒ‡æ¨™
- **æ•¸æ“šå®Œæ•´æ€§**ï¼š> 95%çš„äº¤æ˜“æ—¥æœ‰å®Œæ•´æ•¸æ“š
- **æ›´æ–°åŠæ™‚æ€§**ï¼šæ•¸æ“šå»¶é² < 30åˆ†é˜
- **æº–ç¢ºæ€§**ï¼šèˆ‡å®˜æ–¹æ•¸æ“šå·®ç•° < 0.1%

### ç³»çµ±æ€§èƒ½æŒ‡æ¨™
- **è™•ç†é€Ÿåº¦**ï¼šç‰¹å¾µè¨ˆç®— < 5ç§’
- **è¨˜æ†¶é«”ä½¿ç”¨**ï¼š< 2GB
- **ç©©å®šæ€§**ï¼š7Ã—24å°æ™‚é‹è¡Œç„¡ä¸­æ–·

---

## ğŸš€ æœªä¾†æ“´å±•æ–¹å‘

### 1. æ›´å¤šæ›¿ä»£æ•¸æ“šæº
- **è¡›æ˜Ÿæ•¸æ“š**ï¼šåœè»Šå ´è¡›æ˜Ÿåœ–åƒåˆ†ææ¶ˆè²»è¶¨å‹¢
- **ç¤¾äº¤åª’é«”æƒ…ç·’**ï¼šTwitterã€å¾®åšæƒ…ç·’æŒ‡æ¨™
- **æœç´¢è¶¨å‹¢**ï¼šGoogle Trendsã€ç™¾åº¦æŒ‡æ•¸
- **å°ˆåˆ©æ•¸æ“š**ï¼šç§‘æŠ€å…¬å¸å‰µæ–°æŒ‡æ¨™

### 2. æ©Ÿå™¨å­¸ç¿’æ•´åˆ
- **ç‰¹å¾µè‡ªå‹•åŒ–**ï¼šAutoMLç‰¹å¾µå·¥ç¨‹
- **æ·±åº¦å­¸ç¿’**ï¼šLSTMé æ¸¬æœŸè²¨åƒ¹å·®
- **å¼·åŒ–å­¸ç¿’**ï¼šå‹•æ…‹å€‰ä½é…ç½®

### 3. å¯¦æ™‚äº¤æ˜“ç³»çµ±
- **APIæ•´åˆ**ï¼šåˆ¸å•†äº¤æ˜“API
- **é¢¨éšªç›£æ§**ï¼šå¯¦æ™‚é¢¨éšªæŒ‡æ¨™
- **è‡ªå‹•åŸ·è¡Œ**ï¼šä¿¡è™Ÿè‡ªå‹•ä¸‹å–®

### 4. è·¨å¸‚å ´åˆ†æ
- **Aè‚¡è¯å‹•**ï¼šæ»¬æ·±æ¸¯é€šè³‡é‡‘æµ
- **ç¾è‚¡æœŸè²¨**ï¼šVIXææ…ŒæŒ‡æ•¸
- **å•†å“æœŸè²¨**ï¼šé»ƒé‡‘ã€åŸæ²¹é—œè¯æ€§

---

## ğŸ’¡ é—œéµæˆåŠŸå› ç´ 

### æŠ€è¡“å±¤é¢
1. **æ•¸æ“šåŒæ­¥ç²¾åº¦**ï¼šç¢ºä¿ä¸åŒæ•¸æ“šæºæ™‚é–“æˆ³æº–ç¢ºå°é½Š
2. **ç‰¹å¾µç©©å®šæ€§**ï¼šé¿å…éæ“¬åˆï¼Œå»ºç«‹robustnessæ¸¬è©¦
3. **æ€§èƒ½å„ªåŒ–**ï¼šä½¿ç”¨å‘é‡åŒ–æ“ä½œå’Œä¸¦è¡Œè™•ç†
4. **éŒ¯èª¤è™•ç†**ï¼šå»ºç«‹å®Œå–„çš„ç•°å¸¸æ•æ‰æ©Ÿåˆ¶

### æ¥­å‹™å±¤é¢
1. **å› å­æœ‰æ•ˆæ€§**ï¼šå®šæœŸé©—è­‰å› å­é æ¸¬èƒ½åŠ›
2. **äº¤æ˜“æˆæœ¬**ï¼šè€ƒæ…®å¯¦éš›äº¤æ˜“æ‰‹çºŒè²»å’Œè¡æ“Šæˆæœ¬
3. **å¸‚å ´ç’°å¢ƒ**ï¼šé©æ‡‰ä¸åŒå¸‚å ´éšæ®µï¼ˆç‰›ç†Šå¸‚ï¼‰
4. **åˆè¦è¦æ±‚**ï¼šéµå®ˆé¦™æ¸¯è­‰ç›£æœƒç›¸é—œè¦å®š

### é‹ç‡Ÿå±¤é¢
1. **ç›£æ§å‘Šè­¦**ï¼šå»ºç«‹æ•¸æ“šç•°å¸¸å’Œç³»çµ±æ•…éšœå‘Šè­¦
2. **æ–‡æª”ç¶­è­·**ï¼šè©³ç´°è¨˜éŒ„æ‰€æœ‰ä¿®æ”¹å’Œé…ç½®
3. **å®šæœŸæª¢æŸ¥**ï¼šæ¯æœˆé€²è¡Œç³»çµ±å¥åº·æª¢æŸ¥
4. **å‚™ä»½æ¢å¾©**ï¼šå»ºç«‹æ•¸æ“šå’Œç³»çµ±å‚™ä»½æ–¹æ¡ˆ

---

## ğŸ“‹ æª¢æŸ¥æ¸…å–®

### é–‹ç™¼å®Œæˆæª¢æŸ¥
- [ ] æœŸè²¨æ•¸æ“šç²å–åŠŸèƒ½æ­£å¸¸
- [ ] æ—¥å¤œåƒ¹å·®è¨ˆç®—æº–ç¢º
- [ ] æ•¸æ“šåŒæ­¥ç„¡æ™‚é–“åç§»
- [ ] ç‰¹å¾µå·¥ç¨‹ç®¡é“é‹è¡Œé †æš¢
- [ ] å¤šå› å­ç­–ç•¥é‚è¼¯æ­£ç¢º
- [ ] æœŸç¾å¥—åˆ©ç­–ç•¥å¯ç”¨
- [ ] å„€è¡¨æ¿é¡¯ç¤ºéåƒ¹æ ¼æ•¸æ“š
- [ ] æ‰€æœ‰å–®å…ƒæ¸¬è©¦é€šé
- [ ] å›æ¸¬çµæœç¬¦åˆé æœŸ
- [ ] ç³»çµ±æ€§èƒ½æ»¿è¶³è¦æ±‚

### éƒ¨ç½²å‰æª¢æŸ¥
- [ ] ç”Ÿç”¢ç’°å¢ƒé…ç½®å®Œæˆ
- [ ] æ•¸æ“šæºAPIæ¬Šé™ç²å–
- [ ] ç›£æ§ç³»çµ±éƒ¨ç½²
- [ ] å‚™ä»½æ©Ÿåˆ¶å»ºç«‹
- [ ] æ–‡æª”æ›´æ–°å®Œæ•´
- [ ] åœ˜éšŠåŸ¹è¨“å®Œæˆ

é€™å€‹æŒ‡å—æä¾›äº†ä¸€å€‹å®Œæ•´çš„éåƒ¹æ ¼æ•¸æ“šæ•´åˆæ¡†æ¶ï¼Œå¯ä»¥å¹«åŠ©æ‚¨çš„ç³»çµ±å¾å‚³çµ±çš„åƒ¹æ ¼é©…å‹•ç­–ç•¥é€²åŒ–ç‚ºå¤šå› å­ã€å¤šæ•¸æ“šæºçš„ç¾ä»£é‡åŒ–äº¤æ˜“å¹³å°ï¼Œå¤§å¹…æå‡ç­–ç•¥çš„å¤æ™®æ¯”ç‡å’ŒAlphaç”Ÿæˆèƒ½åŠ›ã€‚

---

## ğŸŒŸ å…¶ä»–é«˜ç´šç­–ç•¥é¡å‹

### 1. å®è§€ç¶“æ¿Ÿç­–ç•¥ ğŸ’¹

#### 1.1 åˆ©ç‡ç’°å¢ƒç­–ç•¥
```python
# enhanced_strategies/macro_strategies.py
class InterestRateStrategy:
    """åˆ©ç‡ç’°å¢ƒç­–ç•¥"""
    
    def __init__(self):
        self.data_sources = {
            'fed_rate': 'FRED API - ç¾è¯å„²åˆ©ç‡',
            'hkma_rate': 'HKMA - é¦™æ¸¯åŸºæº–åˆ©ç‡', 
            'pboc_rate': 'äººæ°‘éŠ€è¡Œ - ä¸­åœ‹åŸºæº–åˆ©ç‡',
            'yield_curve': 'ç¾åœ‹åœ‹å‚µæ”¶ç›Šç‡æ›²ç·š',
            'credit_spreads': 'ä¿¡ç”¨åˆ©å·®æ•¸æ“š'
        }
        
    def generate_signals(self, rate_data, stock_data):
        """åŸºæ–¼åˆ©ç‡è®ŠåŒ–ç”Ÿæˆäº¤æ˜“ä¿¡è™Ÿ"""
        signals = {}
        
        # åˆ©ç‡ä¸Šå‡æ™‚çš„é˜²ç¦¦æ€§è‚¡ç¥¨åå¥½
        if self._is_rate_rising(rate_data):
            signals['banking_stocks'] = 'BUY'  # éŠ€è¡Œè‚¡å—ç›Š
            signals['reit_stocks'] = 'SELL'    # REITså—å£“
            signals['growth_stocks'] = 'REDUCE' # æˆé•·è‚¡ä¼°å€¼å£“ç¸®
            
        # åˆ©ç‡ä¸‹é™æ™‚çš„æˆé•·è‚¡åå¥½  
        elif self._is_rate_falling(rate_data):
            signals['growth_stocks'] = 'BUY'   # æˆé•·è‚¡å—ç›Š
            signals['reit_stocks'] = 'BUY'     # REITså—ç›Š
            signals['banking_stocks'] = 'REDUCE' # éŠ€è¡Œè‚¡æ¯å·®æ”¶çª„
            
        return signals
```

#### 1.2 åŒ¯ç‡å¥—åˆ©ç­–ç•¥
```python
class CurrencyArbitrageStrategy:
    """åŒ¯ç‡å¥—åˆ©ç­–ç•¥"""
    
    def __init__(self):
        self.currency_pairs = {
            'USDCNY': 'ç¾å…ƒäººæ°‘å¹£',
            'USDHKD': 'ç¾å…ƒæ¸¯å…ƒ',
            'EURCNY': 'æ­å…ƒäººæ°‘å¹£',
            'JPYCNY': 'æ—¥å…ƒäººæ°‘å¹£'
        }
        
    def identify_arbitrage_opportunities(self, fx_data, stock_data):
        """è­˜åˆ¥åŒ¯ç‡å¥—åˆ©æ©Ÿæœƒ"""
        opportunities = []
        
        # AHè‚¡å¥—åˆ©
        ah_premium = self._calculate_ah_premium(stock_data)
        usdcny_rate = fx_data['USDCNY']
        
        if ah_premium > 0.15:  # Aè‚¡æº¢åƒ¹è¶…é15%
            opportunities.append({
                'type': 'AH_arbitrage',
                'action': 'LONG_H_SHORT_A',
                'expected_return': ah_premium * 0.3,
                'risk_level': 'MEDIUM'
            })
            
        return opportunities
```

### 2. äº‹ä»¶é©…å‹•ç­–ç•¥ ğŸ“ˆ

#### 2.1 è²¡å ±äº‹ä»¶ç­–ç•¥
```python
class EarningsEventStrategy:
    """è²¡å ±äº‹ä»¶ç­–ç•¥"""
    
    def __init__(self):
        self.earnings_calendar = self._load_earnings_calendar()
        self.event_windows = {
            'pre_earnings': (-10, -1),   # è²¡å ±å‰10-1å¤©
            'earnings_day': (0, 0),      # è²¡å ±ç•¶å¤©
            'post_earnings': (1, 5)      # è²¡å ±å¾Œ1-5å¤©
        }
        
    def earnings_momentum_strategy(self, symbol, earnings_data):
        """è²¡å ±å‹•é‡ç­–ç•¥"""
        signals = []
        
        # è²¡å ±å‰é æœŸå»ºå€‰
        if self._is_positive_guidance(earnings_data):
            signals.append({
                'symbol': symbol,
                'action': 'BUY',
                'window': 'pre_earnings',
                'confidence': 0.7,
                'reason': 'æ­£é¢æ¥­ç¸¾æŒ‡å¼•'
            })
            
        # è²¡å ±å¾Œè¶¨å‹¢è·Ÿéš¨
        surprise_factor = self._calculate_earnings_surprise(earnings_data)
        if surprise_factor > 0.05:  # æ¥­ç¸¾è¶…é æœŸ5%ä»¥ä¸Š
            signals.append({
                'symbol': symbol,
                'action': 'HOLD_EXTEND',
                'window': 'post_earnings',
                'confidence': 0.8,
                'reason': f'æ¥­ç¸¾è¶…é æœŸ{surprise_factor:.1%}'
            })
            
        return signals
```

#### 2.2 ç›£ç®¡æ”¿ç­–ç­–ç•¥
```python
class RegulatoryEventStrategy:
    """ç›£ç®¡æ”¿ç­–äº‹ä»¶ç­–ç•¥"""
    
    def __init__(self):
        self.policy_categories = {
            'fintech_regulation': ['1024.HK', '9988.HK', '700.HK'],
            'healthcare_policy': ['2269.HK', '1833.HK'],
            'property_policy': ['1109.HK', '1997.HK', '0016.HK'],
            'education_policy': ['1797.HK', '9901.HK']
        }
        
    def monitor_policy_impact(self, policy_events, sector_performance):
        """ç›£æ§æ”¿ç­–å½±éŸ¿"""
        alerts = []
        
        for event in policy_events:
            affected_sectors = self._identify_affected_sectors(event)
            
            for sector in affected_sectors:
                impact_score = self._calculate_policy_impact(event, sector)
                
                if abs(impact_score) > 0.1:  # å½±éŸ¿è¶…é10%
                    alerts.append({
                        'event': event['title'],
                        'sector': sector,
                        'impact_score': impact_score,
                        'recommended_action': 'REDUCE' if impact_score < 0 else 'INCREASE',
                        'affected_stocks': self.policy_categories.get(sector, [])
                    })
                    
        return alerts
```

### 3. è·¨å¸‚å ´å¥—åˆ©ç­–ç•¥ ğŸŒ

#### 3.1 AHè‚¡å¥—åˆ©ç­–ç•¥  
```python
class AHStockArbitrageStrategy:
    """Aè‚¡Hè‚¡å¥—åˆ©ç­–ç•¥"""
    
    def __init__(self):
        self.ah_pairs = {
            '939.HK': '601939.SS',    # å»ºè¨­éŠ€è¡Œ
            '1398.HK': '601398.SS',   # å·¥å•†éŠ€è¡Œ
            '3988.HK': '601988.SS',   # ä¸­åœ‹éŠ€è¡Œ
            '2318.HK': '601318.SS',   # ä¸­åœ‹å¹³å®‰
            '1109.HK': '001209.SZ'    # è¯æ½¤ç½®åœ°
        }
        
    def calculate_ah_premium(self, h_price, a_price, fx_rate):
        """è¨ˆç®—AHè‚¡æº¢åƒ¹"""
        # è½‰æ›Aè‚¡åƒ¹æ ¼åˆ°æ¸¯å¹£
        a_price_hkd = a_price * fx_rate
        premium = (h_price - a_price_hkd) / a_price_hkd
        return premium
        
    def generate_arbitrage_signals(self, price_data, fx_data):
        """ç”Ÿæˆå¥—åˆ©ä¿¡è™Ÿ"""
        signals = []
        
        for h_symbol, a_symbol in self.ah_pairs.items():
            premium = self.calculate_ah_premium(
                price_data[h_symbol]['close'],
                price_data[a_symbol]['close'], 
                fx_data['CNYHHK']
            )
            
            # å¥—åˆ©é–¾å€¼
            if premium > 0.15:  # Hè‚¡æº¢åƒ¹è¶…é15%
                signals.append({
                    'type': 'AH_ARBITRAGE',
                    'long_symbol': a_symbol,
                    'short_symbol': h_symbol,
                    'premium': premium,
                    'expected_return': premium * 0.5,
                    'risk': 'MEDIUM'
                })
                
        return signals
```

### 4. é«˜é »é‡åŒ–ç­–ç•¥ âš¡

#### 4.1 Level-2æ•¸æ“šç­–ç•¥
```python
class Level2DataStrategy:
    """åŸºæ–¼Level-2æ•¸æ“šçš„é«˜é »ç­–ç•¥"""
    
    def __init__(self):
        self.tick_size = 0.01  # æ¸¯è‚¡æœ€å°åƒ¹æ ¼è®Šå‹•
        self.order_book_levels = 10
        
    def order_book_imbalance_strategy(self, order_book_data):
        """è¨‚å–®ç°¿å¤±è¡¡ç­–ç•¥"""
        signals = []
        
        # è¨ˆç®—è²·è³£ç›¤å¤±è¡¡
        bid_volume = sum(order_book_data['bids']['volume'][:5])
        ask_volume = sum(order_book_data['asks']['volume'][:5]) 
        
        imbalance_ratio = (bid_volume - ask_volume) / (bid_volume + ask_volume)
        
        if imbalance_ratio > 0.3:  # è²·ç›¤æ˜é¡¯å¼·æ–¼è³£ç›¤
            signals.append({
                'action': 'BUY',
                'strategy': 'order_imbalance',
                'confidence': min(0.9, imbalance_ratio),
                'hold_period': '1-5min'
            })
            
        elif imbalance_ratio < -0.3:  # è³£ç›¤æ˜é¡¯å¼·æ–¼è²·ç›¤
            signals.append({
                'action': 'SELL',
                'strategy': 'order_imbalance', 
                'confidence': min(0.9, abs(imbalance_ratio)),
                'hold_period': '1-5min'
            })
            
        return signals
```

### 5. å¦é¡æ•¸æ“šç­–ç•¥ ğŸ›°ï¸

#### 5.1 è¡›æ˜Ÿæ•¸æ“šç­–ç•¥
```python
class SatelliteDataStrategy:
    """è¡›æ˜Ÿæ•¸æ“šç­–ç•¥"""
    
    def __init__(self):
        self.satellite_indicators = {
            'parking_lots': 'è³¼ç‰©ä¸­å¿ƒåœè»Šå ´è¡›æ˜Ÿåœ–åƒ',
            'factory_activity': 'å·¥å» æ´»å‹•ç†±åŠ›åœ–',
            'port_traffic': 'æ¸¯å£è²¨æ«ƒæµé‡',
            'construction_sites': 'å»ºç¯‰å·¥åœ°æ´»å‹•æ°´å¹³'
        }
        
    def retail_traffic_analysis(self, satellite_data, retail_stocks):
        """é›¶å”®æµé‡åˆ†æ"""
        signals = []
        
        # åˆ†æè³¼ç‰©ä¸­å¿ƒäººæµ
        for location in satellite_data['shopping_centers']:
            traffic_trend = self._calculate_traffic_trend(location['images'])
            
            if traffic_trend > 0.2:  # äººæµå¢é•·20%ä»¥ä¸Š
                # æ‰¾åˆ°ç›¸é—œé›¶å”®è‚¡
                related_stocks = self._map_location_to_stocks(location, retail_stocks)
                
                for stock in related_stocks:
                    signals.append({
                        'symbol': stock,
                        'action': 'BUY',
                        'data_source': 'satellite_traffic',
                        'confidence': 0.6,
                        'reason': f'{location["name"]}äººæµå¢é•·{traffic_trend:.1%}'
                    })
                    
        return signals
```

#### 5.2 ç¤¾äº¤åª’é«”æƒ…ç·’ç­–ç•¥
```python
class SocialSentimentStrategy:
    """ç¤¾äº¤åª’é«”æƒ…ç·’ç­–ç•¥"""
    
    def __init__(self):
        self.sentiment_sources = {
            'weibo': 'å¾®åšæƒ…ç·’æŒ‡æ•¸',
            'wechat': 'å¾®ä¿¡å…¬çœ¾è™Ÿæ–‡ç« æƒ…ç·’',
            'reddit': 'Redditè¨è«–æƒ…ç·’',
            'news': 'è²¡ç¶“æ–°èæƒ…ç·’'
        }
        
    def sentiment_momentum_strategy(self, sentiment_data, stock_symbols):
        """æƒ…ç·’å‹•é‡ç­–ç•¥"""
        signals = []
        
        for symbol in stock_symbols:
            # ç²å–è©²è‚¡ç¥¨çš„æƒ…ç·’æ•¸æ“š
            stock_sentiment = sentiment_data.get(symbol, {})
            
            # è¨ˆç®—æƒ…ç·’è®ŠåŒ–è¶¨å‹¢
            sentiment_score = self._calculate_sentiment_score(stock_sentiment)
            sentiment_momentum = self._calculate_sentiment_momentum(stock_sentiment)
            
            # ç”Ÿæˆäº¤æ˜“ä¿¡è™Ÿ
            if sentiment_score > 0.7 and sentiment_momentum > 0.3:
                signals.append({
                    'symbol': symbol,
                    'action': 'BUY',
                    'strategy': 'sentiment_momentum',
                    'confidence': sentiment_score,
                    'data_source': 'social_media',
                    'reason': f'æ­£é¢æƒ…ç·’ä¸”å‹•é‡å¼·å‹(åˆ†æ•¸:{sentiment_score:.2f})'
                })
                
        return signals
```

### 6. ESGä¸»é¡Œç­–ç•¥ ğŸŒ±

#### 6.1 ç¶ è‰²é‡‘èç­–ç•¥
```python
class ESGStrategy:
    """ESGä¸»é¡ŒæŠ•è³‡ç­–ç•¥"""
    
    def __init__(self):
        self.esg_factors = {
            'carbon_emissions': 'ç¢³æ’æ”¾æ•¸æ“š',
            'renewable_energy': 'å¯å†ç”Ÿèƒ½æºä½¿ç”¨æ¯”ä¾‹', 
            'board_diversity': 'è‘£äº‹æœƒå¤šå…ƒåŒ–',
            'worker_safety': 'å·¥äººå®‰å…¨è¨˜éŒ„'
        }
        
    def green_finance_screening(self, esg_data, stock_universe):
        """ç¶ è‰²é‡‘èç¯©é¸"""
        green_portfolio = []
        
        for symbol in stock_universe:
            esg_score = esg_data.get(symbol, {})
            
            # ESGè©•åˆ†æ¨™æº–
            if (esg_score.get('environmental', 0) > 70 and
                esg_score.get('social', 0) > 60 and
                esg_score.get('governance', 0) > 65):
                
                green_portfolio.append({
                    'symbol': symbol,
                    'esg_score': esg_score,
                    'green_rank': self._calculate_green_rank(esg_score),
                    'recommended_weight': self._calculate_esg_weight(esg_score)
                })
                
        return sorted(green_portfolio, key=lambda x: x['green_rank'], reverse=True)
```

### 7. æ•¸æ“šç²å–èˆ‡æ•´åˆæ–¹æ¡ˆ ğŸ“¡

#### 7.1 æ•¸æ“šæºå°æ‡‰è¡¨
```python
DATA_SOURCE_MAPPING = {
    # åŸºç¤å¸‚å ´æ•¸æ“š
    'stock_prices': 'Yahoo Finance / Wind / Bloomberg',
    'futures_data': 'HKEX / CME / Wind API',
    
    # å®è§€ç¶“æ¿Ÿæ•¸æ“š  
    'interest_rates': 'FRED API / HKMA / PBOC',
    'fx_rates': 'Yahoo Finance / OANDA API',
    'economic_indicators': 'FRED / Wind / Choice',
    
    # ä¼æ¥­åŸºæœ¬é¢æ•¸æ“š
    'earnings_data': 'Wind / Bloomberg / FactSet',
    'financial_statements': 'HKEXæŠ«éœ²æ˜“ / Wind',
    'analyst_estimates': 'I/B/E/S / FactSet',
    
    # å¦é¡æ•¸æ“š
    'satellite_data': 'Planet Labs / Maxar / RS Metrics',
    'social_sentiment': 'Twitter API / å¾®åšAPI / è‡ªå»ºçˆ¬èŸ²',
    'patent_data': 'USPTO / CNIPA / æ™ºæ…§èŠ½',
    'supply_chain': 'FactSetä¾›æ‡‰éˆ / Windç”¢æ¥­éˆ',
    
    # ESGæ•¸æ“š
    'esg_scores': 'MSCI ESG / Sustainalytics / Wind ESG',
    'carbon_data': 'CDP / ä¼æ¥­ESGå ±å‘Š',
    
    # é«˜é »æ•¸æ“š
    'level2_data': 'HKEX Market Data / Windå¯¦æ™‚',
    'options_data': 'HKEX / WindæœŸæ¬Šæ•¸æ“š'
}
```

#### 7.2 æ•¸æ“šæ›´æ–°èª¿åº¦
```python
# data_scheduler/update_scheduler.py
class DataUpdateScheduler:
    """æ•¸æ“šæ›´æ–°èª¿åº¦å™¨"""
    
    def __init__(self):
        self.update_schedule = {
            'high_frequency': {
                'interval': '1min',
                'sources': ['level2_data', 'futures_tick'],
                'active_hours': '09:30-16:00'
            },
            'daily': {
                'interval': '1day',
                'sources': ['stock_prices', 'economic_indicators'],
                'update_time': '18:00'
            },
            'weekly': {
                'interval': '1week', 
                'sources': ['satellite_data', 'social_sentiment'],
                'update_day': 'Sunday'
            },
            'monthly': {
                'interval': '1month',
                'sources': ['esg_scores', 'patent_data'],
                'update_day': 1
            }
        }
```

### 8. ç­–ç•¥çµ„åˆå„ªåŒ– ğŸ¯

#### 8.1 å¤šç­–ç•¥çµ„åˆ
```python
class StrategyPortfolio:
    """å¤šç­–ç•¥çµ„åˆç®¡ç†"""
    
    def __init__(self):
        self.strategies = {
            'momentum': {'weight': 0.25, 'target_vol': 0.15},
            'mean_reversion': {'weight': 0.20, 'target_vol': 0.12},
            'futures_arbitrage': {'weight': 0.20, 'target_vol': 0.08},
            'sentiment_driven': {'weight': 0.15, 'target_vol': 0.18},
            'macro_rotation': {'weight': 0.20, 'target_vol': 0.14}
        }
        
    def optimize_weights(self, strategy_returns, target_sharpe=2.0):
        """å„ªåŒ–ç­–ç•¥æ¬Šé‡"""
        from scipy.optimize import minimize
        
        def objective(weights):
            portfolio_return = np.sum(strategy_returns.mean() * weights) * 252
            portfolio_vol = np.sqrt(np.dot(weights.T, np.dot(strategy_returns.cov() * 252, weights)))
            sharpe = portfolio_return / portfolio_vol
            return -(sharpe - target_sharpe)**2  # æœ€å¤§åŒ–ç›®æ¨™å¤æ™®æ¯”ç‡
            
        constraints = [
            {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},  # æ¬Šé‡å’Œç‚º1
            {'type': 'ineq', 'fun': lambda x: x}  # éè² æ¬Šé‡
        ]
        
        result = minimize(objective, 
                         x0=np.array(list(self.strategies.values())),
                         method='SLSQP',
                         constraints=constraints)
        
        return result.x
```

#### 8.2 å‹•æ…‹å€‰ä½ç®¡ç†
```python
class DynamicPositionManager:
    """å‹•æ…‹å€‰ä½ç®¡ç†"""
    
    def __init__(self, max_leverage=2.0, risk_budget=0.02):
        self.max_leverage = max_leverage
        self.risk_budget = risk_budget  # æ¯æ—¥VaRé™åˆ¶
        
    def calculate_position_size(self, signal_strength, volatility, correlation_matrix):
        """è¨ˆç®—æœ€å„ªå€‰ä½å¤§å°"""
        # Kellyå…¬å¼è®Šå½¢
        win_rate = self._estimate_win_rate(signal_strength)
        avg_win = self._estimate_avg_return(signal_strength, 'win')
        avg_loss = self._estimate_avg_return(signal_strength, 'loss')
        
        if avg_loss != 0:
            kelly_fraction = win_rate - (1 - win_rate) * avg_win / abs(avg_loss)
        else:
            kelly_fraction = 0
            
        # è€ƒæ…®æ³¢å‹•ç‡èª¿æ•´
        vol_adjusted_size = kelly_fraction / volatility
        
        # è€ƒæ…®çµ„åˆç›¸é—œæ€§
        diversification_factor = self._calculate_diversification_factor(correlation_matrix)
        
        final_size = min(vol_adjusted_size * diversification_factor, self.max_leverage)
        
        return max(0, final_size)  # ç¢ºä¿éè² 
```

é€™å€‹æ“´å±•çš„æŒ‡å—æ¶µè“‹äº†å¾åŸºç¤æ•¸æ“šä¸‹è¼‰åˆ°é«˜ç´šç­–ç•¥é–‹ç™¼çš„å®Œæ•´æ–¹æ¡ˆï¼Œä¸åƒ…åŒ…æ‹¬æœŸè²¨æ•¸æ“šï¼Œé‚„æä¾›äº†å®è§€ç¶“æ¿Ÿã€äº‹ä»¶é©…å‹•ã€è·¨å¸‚å ´å¥—åˆ©ã€é«˜é »äº¤æ˜“ã€å¦é¡æ•¸æ“šå’ŒESGç­‰å¤šç¨®ç­–ç•¥é¡å‹çš„å…·é«”å¯¦ç¾æ–¹æ³•ï¼Œèƒ½å¤ å…¨é¢æå‡æ‚¨çš„é‡åŒ–äº¤æ˜“ç³»çµ±çš„Alphaç”Ÿæˆèƒ½åŠ›ã€‚