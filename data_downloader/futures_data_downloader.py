"""
æ¸¯è‚¡æœŸè²¨æ•¸æ“šä¸‹è¼‰å™¨
ç²å–æ†ç”ŸæŒ‡æ•¸æœŸè²¨ã€åœ‹ä¼æŒ‡æ•¸æœŸè²¨ç­‰ç›¸é—œæœŸè²¨æ•¸æ“š
"""

import yfinance as yf
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timedelta
import os
import sys
import warnings
warnings.filterwarnings('ignore')

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import logger, NON_PRICE_CONFIG
from data_handler import TechnicalIndicators

class HKFuturesDataDownloader:
    """æ¸¯è‚¡æœŸè²¨æ•¸æ“šä¸‹è¼‰å™¨"""
    
    def __init__(self, data_dir: str = "data_output/futures"):
        from pathlib import Path
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # å¾é…ç½®ç²å–æœŸè²¨åˆç´„
        self.futures_symbols = NON_PRICE_CONFIG.hk_futures_symbols
        
        # æ“´å±•æœŸè²¨åˆç´„æ˜ å°„
        self.extended_futures = {
            # æ†ç”ŸæŒ‡æ•¸ç›¸é—œ
            '^HSI': 'æ†ç”ŸæŒ‡æ•¸',
            'HSI=F': 'æ†ç”ŸæŒ‡æ•¸æœŸè²¨ä¸»åŠ›åˆç´„',
            
            # åœ‹ä¼æŒ‡æ•¸ç›¸é—œ  
            '^HSCE': 'æ†ç”Ÿåœ‹ä¼æŒ‡æ•¸',
            'HSCE=F': 'åœ‹ä¼æŒ‡æ•¸æœŸè²¨ä¸»åŠ›åˆç´„',
            
            # ç§‘æŠ€æŒ‡æ•¸ç›¸é—œ
            '^HSTECH': 'æ†ç”Ÿç§‘æŠ€æŒ‡æ•¸',
            'HSTECH=F': 'ç§‘æŠ€æŒ‡æ•¸æœŸè²¨ä¸»åŠ›åˆç´„',
            
            # å°å‹æ†æŒ‡æœŸè²¨
            'MHI=F': 'å°å‹æ†æŒ‡æœŸè²¨ä¸»åŠ›åˆç´„',
            
            # ä¸­è¯120æŒ‡æ•¸
            '^HSC120': 'ä¸­è¯120æŒ‡æ•¸',
            
            # ç›¸é—œETFä½œç‚ºæ›¿ä»£
            '2800.HK': 'ç›ˆå¯ŒåŸºé‡‘ETF',
            '2828.HK': 'æ†ç”Ÿåœ‹ä¼ETF',
            '3067.HK': 'æ†ç”Ÿç§‘æŠ€ETF'
        }
        
    def download_futures_data(self, 
                            symbol: str, 
                            start_date: str,
                            end_date: str,
                            interval: str = "1d") -> Optional[pd.DataFrame]:
        """ä¸‹è¼‰æœŸè²¨æ•¸æ“š"""
        try:
            logger.info(f"æ­£åœ¨ä¸‹è¼‰æœŸè²¨æ•¸æ“š: {symbol}")
            
            ticker = yf.Ticker(symbol)
            data = ticker.history(start=start_date, end=end_date, interval=interval)
            
            if data.empty:
                logger.warning(f"âŒ {symbol} æ²’æœ‰ç²å–åˆ°æœŸè²¨æ•¸æ“š")
                return None
                
            # æ•¸æ“šæ¸…ç†
            data = data.dropna()
            
            # æ·»åŠ å…ƒæ•¸æ“š
            data['Symbol'] = symbol
            data['Contract_Name'] = self.extended_futures.get(symbol, symbol)
            data['Data_Type'] = 'futures'
            
            # è¨ˆç®—é¡å¤–æŒ‡æ¨™
            data['Price_Change'] = data['Close'].diff()
            data['Price_Change_Pct'] = data['Close'].pct_change() * 100
            data['Volatility'] = data['Close'].rolling(window=20).std()
            
            # é‡æ–°æ’åˆ—åˆ—
            columns_order = ['Symbol', 'Contract_Name', 'Data_Type', 'Open', 'High', 
                           'Low', 'Close', 'Volume', 'Price_Change', 'Price_Change_Pct', 
                           'Volatility']
            
            available_columns = [col for col in columns_order if col in data.columns]
            data = data[available_columns]
            
            # ä¿å­˜æ•¸æ“š
            filename = f"{symbol.replace('=', '_').replace('^', '').replace('.', '_')}_futures.csv"
            filepath = self.data_dir / filename
            data.to_csv(filepath)
            logger.info(f"âœ… {symbol} æœŸè²¨æ•¸æ“šå·²ä¿å­˜åˆ° {filepath}")
            
            return data
            
        except Exception as e:
            logger.error(f"âŒ ä¸‹è¼‰ {symbol} æœŸè²¨æ•¸æ“šå¤±æ•—: {e}")
            return None
    
    def download_all_futures(self, 
                           start_date: str = "2023-01-01",
                           end_date: str = None,
                           interval: str = "1d") -> Dict[str, pd.DataFrame]:
        """æ‰¹é‡ä¸‹è¼‰æ‰€æœ‰æœŸè²¨æ•¸æ“š"""
        if end_date is None:
            end_date = datetime.now().strftime('%Y-%m-%d')
            
        logger.info(f"é–‹å§‹æ‰¹é‡ä¸‹è¼‰æœŸè²¨æ•¸æ“š...")
        logger.info(f"æ™‚é–“ç¯„åœ: {start_date} åˆ° {end_date}")
        
        all_futures_data = {}
        failed_downloads = []
        
        for symbol in self.extended_futures.keys():
            data = self.download_futures_data(symbol, start_date, end_date, interval)
            
            if data is not None:
                all_futures_data[symbol] = data
            else:
                failed_downloads.append(symbol)
                
            # æ·»åŠ å»¶é²
            import time
            time.sleep(NON_PRICE_CONFIG.download_delay_seconds)
        
        self._generate_futures_report(all_futures_data, failed_downloads)
        return all_futures_data
    
    def calculate_futures_indicators(self, data: pd.DataFrame) -> pd.DataFrame:
        """è¨ˆç®—æœŸè²¨æŠ€è¡“æŒ‡æ¨™"""
        try:
            # ç§»å‹•å¹³å‡ç·š
            data['MA5'] = data['Close'].rolling(window=5).mean()
            data['MA20'] = data['Close'].rolling(window=20).mean()
            data['MA60'] = data['Close'].rolling(window=60).mean()
            
            # å¸ƒæ—å¸¶
            data['BB_Middle'] = data['Close'].rolling(window=20).mean()
            bb_std = data['Close'].rolling(window=20).std()
            data['BB_Upper'] = data['BB_Middle'] + (bb_std * 2)
            data['BB_Lower'] = data['BB_Middle'] - (bb_std * 2)
            
            # RSI
            delta = data['Close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            data['RSI'] = 100 - (100 / (1 + rs))
            
            # MACD
            exp1 = data['Close'].ewm(span=12).mean()
            exp2 = data['Close'].ewm(span=26).mean()
            data['MACD'] = exp1 - exp2
            data['MACD_Signal'] = data['MACD'].ewm(span=9).mean()
            data['MACD_Histogram'] = data['MACD'] - data['MACD_Signal']
            
            return data
            
        except Exception as e:
            logger.error(f"è¨ˆç®—æœŸè²¨æŠ€è¡“æŒ‡æ¨™å¤±æ•—: {e}")
            return data
    
    def analyze_futures_correlation(self, 
                                  all_data: Dict[str, pd.DataFrame],
                                  target_stock: str = "2800.HK") -> pd.DataFrame:
        """åˆ†ææœŸè²¨èˆ‡ç›®æ¨™è‚¡ç¥¨çš„ç›¸é—œæ€§"""
        try:
            correlation_results = []
            
            # ç²å–ç›®æ¨™è‚¡ç¥¨æ•¸æ“šä½œç‚ºåŸºæº–
            if target_stock not in all_data:
                logger.warning(f"ç›®æ¨™è‚¡ç¥¨ {target_stock} æ•¸æ“šä¸å­˜åœ¨")
                return pd.DataFrame()
                
            target_data = all_data[target_stock]['Close']
            
            for symbol, futures_data in all_data.items():
                if symbol == target_stock:
                    continue
                    
                futures_close = futures_data['Close']
                
                # å°é½Šæ•¸æ“š
                aligned_data = pd.concat([target_data, futures_close], axis=1, join='inner')
                aligned_data.columns = ['target', 'futures']
                aligned_data = aligned_data.dropna()
                
                if len(aligned_data) < 20:  # éœ€è¦è¶³å¤ çš„æ•¸æ“šé»
                    continue
                    
                # è¨ˆç®—ç›¸é—œæ€§
                correlation = aligned_data['target'].corr(aligned_data['futures'])
                
                # è¨ˆç®—æ»¾å‹•ç›¸é—œæ€§
                rolling_corr = aligned_data['target'].rolling(window=20).corr(aligned_data['futures'])
                avg_rolling_corr = rolling_corr.mean()
                
                correlation_results.append({
                    'Futures_Symbol': symbol,
                    'Contract_Name': self.extended_futures.get(symbol, symbol),
                    'Correlation': round(correlation, 4),
                    'Avg_Rolling_Correlation': round(avg_rolling_corr, 4),
                    'Data_Points': len(aligned_data),
                    'Correlation_Strength': self._categorize_correlation(correlation)
                })
            
            results_df = pd.DataFrame(correlation_results)
            results_df = results_df.sort_values('Correlation', key=abs, ascending=False)
            
            # ä¿å­˜ç›¸é—œæ€§åˆ†æçµæœ
            filepath = self.data_dir / f"futures_correlation_analysis_{datetime.now().strftime('%Y%m%d')}.csv"
            results_df.to_csv(filepath, index=False)
            logger.info(f"ç›¸é—œæ€§åˆ†æçµæœå·²ä¿å­˜åˆ°: {filepath}")
            
            return results_df
            
        except Exception as e:
            logger.error(f"æœŸè²¨ç›¸é—œæ€§åˆ†æå¤±æ•—: {e}")
            return pd.DataFrame()
    
    def _categorize_correlation(self, correlation: float) -> str:
        """åˆ†é¡ç›¸é—œæ€§å¼·åº¦"""
        abs_corr = abs(correlation)
        if abs_corr >= 0.8:
            return "éå¸¸å¼·"
        elif abs_corr >= 0.6:
            return "å¼·"
        elif abs_corr >= 0.4:
            return "ä¸­ç­‰"
        elif abs_corr >= 0.2:
            return "å¼±"
        else:
            return "éå¸¸å¼±"
    
    def generate_futures_features(self, 
                                all_data: Dict[str, pd.DataFrame]) -> pd.DataFrame:
        """ç”ŸæˆæœŸè²¨ç‰¹å¾µæ•¸æ“šé›†"""
        try:
            features_list = []
            
            for symbol, data in all_data.items():
                # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
                data_with_indicators = self.calculate_futures_indicators(data.copy())
                
                # é¸æ“‡ç‰¹å¾µåˆ—
                feature_columns = ['Close', 'Volume', 'Volatility', 'Price_Change_Pct',
                                 'MA5', 'MA20', 'RSI', 'MACD', 'MACD_Signal']
                
                available_features = [col for col in feature_columns if col in data_with_indicators.columns]
                features_data = data_with_indicators[available_features].copy()
                
                # æ·»åŠ æ¨™è­˜
                for col in available_features:
                    features_data[f"{symbol}_{col}"] = features_data[col]
                    
                features_list.append(features_data[[f"{symbol}_{col}" for col in available_features]])
            
            # åˆä½µæ‰€æœ‰ç‰¹å¾µ
            if features_list:
                combined_features = pd.concat(features_list, axis=1, join='outer')
                
                # ä¿å­˜ç‰¹å¾µæ•¸æ“š
                filepath = self.data_dir / f"futures_features_{datetime.now().strftime('%Y%m%d')}.csv"
                combined_features.to_csv(filepath)
                logger.info(f"æœŸè²¨ç‰¹å¾µæ•¸æ“šå·²ä¿å­˜åˆ°: {filepath}")
                
                return combined_features
            else:
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"ç”ŸæˆæœŸè²¨ç‰¹å¾µå¤±æ•—: {e}")
            return pd.DataFrame()
    
    def _generate_futures_report(self, 
                               successful_data: Dict[str, pd.DataFrame],
                               failed_downloads: List[str]):
        """ç”ŸæˆæœŸè²¨æ•¸æ“šä¸‹è¼‰å ±å‘Š"""
        report_lines = [
            "=" * 50,
            "æ¸¯è‚¡æœŸè²¨æ•¸æ“šä¸‹è¼‰å ±å‘Š",
            "=" * 50,
            f"ç¸½å…±å˜—è©¦ä¸‹è¼‰: {len(self.extended_futures)} å€‹æœŸè²¨åˆç´„",
            f"æˆåŠŸä¸‹è¼‰: {len(successful_data)} å€‹åˆç´„",
            f"ä¸‹è¼‰å¤±æ•—: {len(failed_downloads)} å€‹åˆç´„",
            ""
        ]
        
        if successful_data:
            report_lines.append("æˆåŠŸä¸‹è¼‰çš„æœŸè²¨åˆç´„:")
            for symbol in successful_data.keys():
                data_points = len(successful_data[symbol])
                start_date = successful_data[symbol].index.min().strftime('%Y-%m-%d')
                end_date = successful_data[symbol].index.max().strftime('%Y-%m-%d')
                contract_name = self.extended_futures.get(symbol, symbol)
                report_lines.append(f"  {symbol} ({contract_name}): {data_points} å€‹äº¤æ˜“æ—¥ ({start_date} è‡³ {end_date})")
                
        if failed_downloads:
            report_lines.append("\nä¸‹è¼‰å¤±æ•—çš„åˆç´„:")
            for symbol in failed_downloads:
                contract_name = self.extended_futures.get(symbol, symbol)
                report_lines.append(f"  {symbol} ({contract_name})")
                
        report_content = "\n".join(report_lines)
        
        # ä¿å­˜å ±å‘Š
        report_filename = f"futures_download_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        report_filepath = self.data_dir.parent / "reports" / report_filename
        report_filepath.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_filepath, 'w', encoding='utf-8') as f:
            f.write(report_content)
            
        logger.info(f"\n{report_content}")
        logger.info(f"æœŸè²¨æ•¸æ“šä¸‹è¼‰å ±å‘Šå·²ä¿å­˜åˆ°: {report_filepath}")

def main():
    """æ¸¬è©¦æœŸè²¨æ•¸æ“šä¸‹è¼‰å™¨"""
    logger.info("ğŸš€ æ¸¬è©¦æ¸¯è‚¡æœŸè²¨æ•¸æ“šä¸‹è¼‰å™¨...")
    
    downloader = HKFuturesDataDownloader()
    
    # æ¸¬è©¦å–®å€‹æœŸè²¨åˆç´„ä¸‹è¼‰
    start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
    
    # ä¸‹è¼‰æ‰€æœ‰æœŸè²¨æ•¸æ“š
    all_data = downloader.download_all_futures(start_date=start_date)
    
    if all_data:
        logger.info(f"âœ… æˆåŠŸä¸‹è¼‰ {len(all_data)} å€‹æœŸè²¨åˆç´„æ•¸æ“š")
        
        # åˆ†æç›¸é—œæ€§
        correlation_results = downloader.analyze_futures_correlation(all_data)
        if not correlation_results.empty:
            logger.info("âœ… ç›¸é—œæ€§åˆ†æå®Œæˆ")
            logger.info(f"å‰5å€‹æœ€ç›¸é—œçš„æœŸè²¨åˆç´„:")
            print(correlation_results.head())
        
        # ç”Ÿæˆç‰¹å¾µæ•¸æ“š
        features = downloader.generate_futures_features(all_data)
        if not features.empty:
            logger.info(f"âœ… æœŸè²¨ç‰¹å¾µæ•¸æ“šç”Ÿæˆå®Œæˆï¼Œç¶­åº¦: {features.shape}")
    else:
        logger.error("âŒ æœŸè²¨æ•¸æ“šä¸‹è¼‰å¤±æ•—")

if __name__ == "__main__":
    main()