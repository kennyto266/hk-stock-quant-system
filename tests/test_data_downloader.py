"""
æ¸¯è‚¡æ•¸æ“šä¸‹è¼‰å™¨æ¸¬è©¦è…³æœ¬
æ¸¬è©¦æ‰¹é‡ä¸‹è¼‰åŠŸèƒ½å’Œæ•¸æ“šè³ªé‡
"""

import os
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from data_downloader import HKStockDataDownloader
from config import logger
import pandas as pd
from datetime import datetime, timedelta
import yfinance as yf
import datetime as dt
from pathlib import Path
import warnings
from typing import Optional

# ç¦ç”¨è­¦å‘Š
warnings.filterwarnings('ignore')

def test_single_stock():
    """æ¸¬è©¦å–®éš»è‚¡ç¥¨ä¸‹è¼‰"""
    logger.info("ğŸ§ª æ¸¬è©¦å–®éš»è‚¡ç¥¨ä¸‹è¼‰...")
    downloader = HKStockDataDownloader()
    
    # æ¸¬è©¦ä¸‹è¼‰2800.HKï¼ˆç›ˆå¯ŒåŸºé‡‘ï¼‰
    symbol = "2800.HK"
    start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
    end_date = datetime.now().strftime('%Y-%m-%d')
    
    data = downloader.download_single_stock(symbol, start_date, end_date)
    
    if data is not None:
        logger.info(f"âœ… å–®éš»è‚¡ç¥¨æ¸¬è©¦æˆåŠŸ")
        logger.info(f"æ•¸æ“šå½¢ç‹€: {data.shape}")
        logger.info(f"æ•¸æ“šç¯„åœ: {data.index.min()} è‡³ {data.index.max()}")
        logger.info(f"åˆ—å: {list(data.columns)}")
        return True
    else:
        logger.error(f"âŒ å–®éš»è‚¡ç¥¨æ¸¬è©¦å¤±æ•—")
        return False

def test_small_batch():
    """æ¸¬è©¦å°æ‰¹é‡ä¸‹è¼‰"""
    logger.info("ğŸ§ª æ¸¬è©¦å°æ‰¹é‡ä¸‹è¼‰...")
    downloader = HKStockDataDownloader()
    
    # è‡¨æ™‚ä¿®æ”¹è‚¡ç¥¨åˆ—è¡¨ç‚ºå°æ¨£æœ¬
    original_stocks = downloader.hk_stocks
    test_stocks = {
        '2800.HK': 'ç›ˆå¯ŒåŸºé‡‘',
        '700.HK': 'é¨°è¨Šæ§è‚¡',
        '941.HK': 'ä¸­åœ‹ç§»å‹•'
    }
    downloader.hk_stocks = test_stocks
    
    start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
    
    try:
        all_data = downloader.download_all_stocks(start_date=start_date, delay_seconds=0.5)
        
        if len(all_data) > 0:
            logger.info(f"âœ… å°æ‰¹é‡æ¸¬è©¦æˆåŠŸï¼Œä¸‹è¼‰äº† {len(all_data)} éš»è‚¡ç¥¨")
            
            # æ¸¬è©¦åˆä½µæ•¸æ“šé›†
            combined = downloader.create_combined_dataset(all_data)
            if not combined.empty:
                logger.info(f"âœ… åˆä½µæ•¸æ“šé›†æ¸¬è©¦æˆåŠŸï¼Œç¸½å…± {len(combined)} è¡Œæ•¸æ“š")
                return True
            else:
                logger.error("âŒ åˆä½µæ•¸æ“šé›†æ¸¬è©¦å¤±æ•—")
                return False
        else:
            logger.error("âŒ å°æ‰¹é‡æ¸¬è©¦å¤±æ•—ï¼Œæ²’æœ‰ä¸‹è¼‰åˆ°ä»»ä½•æ•¸æ“š")
            return False
            
    finally:
        # æ¢å¾©åŸå§‹è‚¡ç¥¨åˆ—è¡¨
        downloader.hk_stocks = original_stocks

def test_data_quality():
    """æ¸¬è©¦æ•¸æ“šè³ªé‡"""
    logger.info("ğŸ§ª æ¸¬è©¦æ•¸æ“šè³ªé‡...")
    
    # æª¢æŸ¥è¼¸å‡ºç›®éŒ„ä¸­çš„CSVæ–‡ä»¶
    data_dir = Path("data_output/csv")
    
    if not data_dir.exists():
        logger.warning("æ•¸æ“šç›®éŒ„ä¸å­˜åœ¨ï¼Œè·³éè³ªé‡æª¢æŸ¥")
        return True
        
    csv_files = list(data_dir.glob("*.csv"))
    if not csv_files:
        logger.warning("æ²’æœ‰æ‰¾åˆ°CSVæ–‡ä»¶ï¼Œè·³éè³ªé‡æª¢æŸ¥")
        return True
        
    logger.info(f"æª¢æŸ¥ {len(csv_files)} å€‹CSVæ–‡ä»¶...")
    
    for csv_file in csv_files[:3]:  # åªæª¢æŸ¥å‰3å€‹æ–‡ä»¶
        try:
            data = pd.read_csv(csv_file, index_col=0, parse_dates=True)
            
            # æª¢æŸ¥åŸºæœ¬è¦æ±‚
            required_columns = ['Symbol', 'Stock_Name', 'Open', 'High', 'Low', 'Close', 'Volume']
            missing_columns = [col for col in required_columns if col not in data.columns]
            
            if missing_columns:
                logger.error(f"âŒ {csv_file.name} ç¼ºå°‘å¿…éœ€åˆ—: {missing_columns}")
                continue
                
            # æª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§
            if data.isnull().any().any():
                logger.warning(f"âš ï¸ {csv_file.name} å­˜åœ¨ç©ºå€¼")
                
            # æª¢æŸ¥åƒ¹æ ¼é‚è¼¯
            invalid_prices = data[(data['High'] < data['Low']) | 
                                (data['Close'] < 0) | 
                                (data['Volume'] < 0)]
            
            if len(invalid_prices) > 0:
                logger.error(f"âŒ {csv_file.name} å­˜åœ¨ç„¡æ•ˆåƒ¹æ ¼æ•¸æ“š")
                continue
                
            logger.info(f"âœ… {csv_file.name} æ•¸æ“šè³ªé‡æª¢æŸ¥é€šé")
            
        except Exception as e:
            logger.error(f"âŒ æª¢æŸ¥ {csv_file.name} æ™‚å‡ºéŒ¯: {e}")
            continue
            
    return True

def test_hsi_download():
    """æ¸¬è©¦ä¸‹è¼‰æ†ç”ŸæŒ‡æ•¸æ•¸æ“š"""
    print("é–‹å§‹ä¸‹è¼‰æ†ç”ŸæŒ‡æ•¸æ•¸æ“š...")
    
    # è¨­ç½®åƒæ•¸
    index_symbol = '^HSI'
    start_date = dt.datetime(1900, 1, 1)
    end_date = dt.datetime.now()
    
    try:
        # ä¸‹è¼‰æ•¸æ“š
        data: Optional[pd.DataFrame] = yf.download(
            index_symbol,
            start=start_date,
            end=end_date,
            interval='1d',
            progress=True
        )
        
        if data is None or data.empty:
            print("âŒ ä¸‹è¼‰å¤±æ•—ï¼šæ²’æœ‰æ•¸æ“š")
            return
            
        print(f"âœ… æˆåŠŸä¸‹è¼‰æ•¸æ“šï¼")
        print(f"æ•¸æ“šç¯„åœï¼š{data.index.min()} è‡³ {data.index.max()}")
        print(f"ç¸½è¨˜éŒ„æ•¸ï¼š{len(data)}")
        
        # é¡¯ç¤ºæœ€æ–°çš„å¹¾æ¢æ•¸æ“š
        print("\næœ€æ–°æ•¸æ“šï¼š")
        print(data.tail())
        
        # ä¿å­˜æ•¸æ“š
        output_dir = Path("data_output/test")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        csv_path = output_dir / "HSI_test.csv"
        data.to_csv(csv_path)
        print(f"\næ•¸æ“šå·²ä¿å­˜è‡³ï¼š{csv_path}")
        
    except Exception as e:
        print(f"âŒ ä¸‹è¼‰éç¨‹ä¸­å‡ºéŒ¯ï¼š{str(e)}")

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    logger.info("ğŸš€ é–‹å§‹æ¸¯è‚¡æ•¸æ“šä¸‹è¼‰å™¨æ¸¬è©¦...")
    
    tests = [
        ("å–®éš»è‚¡ç¥¨ä¸‹è¼‰", test_single_stock),
        ("å°æ‰¹é‡ä¸‹è¼‰", test_small_batch),
        ("æ•¸æ“šè³ªé‡æª¢æŸ¥", test_data_quality),
        ("æ†ç”ŸæŒ‡æ•¸ä¸‹è¼‰", test_hsi_download)
    ]
    
    results = []
    for test_name, test_func in tests:
        logger.info(f"\n{'='*50}")
        logger.info(f"åŸ·è¡Œæ¸¬è©¦: {test_name}")
        logger.info(f"{'='*50}")
        
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            logger.error(f"âŒ æ¸¬è©¦ {test_name} åŸ·è¡Œå¤±æ•—: {e}")
            results.append((test_name, False))
    
    # è¼¸å‡ºæ¸¬è©¦çµæœ
    logger.info(f"\n{'='*50}")
    logger.info("æ¸¬è©¦çµæœç¸½çµ")
    logger.info(f"{'='*50}")
    
    passed = 0
    for test_name, result in results:
        status = "âœ… é€šé" if result else "âŒ å¤±æ•—"
        logger.info(f"{test_name}: {status}")
        if result:
            passed += 1
            
    logger.info(f"\nç¸½è¨ˆ: {passed}/{len(results)} æ¸¬è©¦é€šé")
    
    if passed == len(results):
        logger.info("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼æ¸¯è‚¡æ•¸æ“šä¸‹è¼‰å™¨æº–å‚™å°±ç·’")
    else:
        logger.warning("âš ï¸ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥é…ç½®å’Œç¶²çµ¡é€£æ¥")

if __name__ == "__main__":
    main()