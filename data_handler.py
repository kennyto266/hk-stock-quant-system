"""
æ¸¯è‚¡é‡åŒ–åˆ†æç³»çµ± - æ•¸æ“šè™•ç†æ¨¡çµ„
åŒ…å«æ•¸æ“šç²å–ã€æŠ€è¡“æŒ‡æ¨™è¨ˆç®—ã€æ•¸æ“šæ¸…ç†ç­‰åŠŸèƒ½
"""

import akshare as ak
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import requests
import json
from typing import Optional, Dict, List, Tuple, Union, Any, cast
import warnings
from config import logger
import time
import logging
import ssl
import urllib3
import os

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')
# å¿½ç•¥SSLé©—è­‰è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def format_date_safely(date_value: Any) -> Optional[str]:
    """å®‰å…¨åœ°æ ¼å¼åŒ–æ—¥æœŸå€¼"""
    if pd.isna(date_value):
        return None
    try:
        if isinstance(date_value, (datetime, pd.Timestamp)):
            return date_value.strftime('%Y-%m-%d')
        return None
    except:
        return None

class DataFetcher:
    """æ•¸æ“šç²å–å™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.data_dir = "data"
        os.makedirs(self.data_dir, exist_ok=True)
        
    def get_stock_file_path(self, symbol: str) -> str:
        """ç²å–è‚¡ç¥¨æ•¸æ“šæ–‡ä»¶è·¯å¾‘"""
        return os.path.join(self.data_dir, f"{symbol}.csv")
        
    def download_stock_data(self, symbol: str, start_date: str, end_date: str) -> None:
        """ä¸‹è¼‰è‚¡ç¥¨æ•¸æ“šä¸¦ä¿å­˜ç‚ºCSV"""
        try:
            # ä½¿ç”¨akshareä¸‹è¼‰æ¸¯è‚¡æ•¸æ“š
            data = ak.stock_hk_hist(symbol=symbol, period="daily", start_date=start_date, end_date=end_date)
            
            if data.empty:
                raise ValueError(f"ç„¡æ³•ç²å– {symbol} çš„æ•¸æ“š")
                
            # é‡å‘½ååˆ—
            data = data.rename(columns={
                'æ—¥æœŸ': 'date',
                'é–‹ç›¤': 'open',
                'æœ€é«˜': 'high',
                'æœ€ä½': 'low',
                'æ”¶ç›¤': 'close',
                'æˆäº¤é‡': 'volume'
            })
            
            # å°‡æ—¥æœŸåˆ—è½‰æ›ç‚ºdatetime
            data['date'] = pd.to_datetime(data['date'])
            
            # ä¿å­˜æ•¸æ“š
            file_path = self.get_stock_file_path(symbol)
            data.to_csv(file_path, index=False)
            
            self.logger.info(f"âœ… æˆåŠŸä¸‹è¼‰ä¸¦ä¿å­˜ {symbol} æ•¸æ“š: {len(data)} å¤©")
            
        except Exception as e:
            self.logger.error(f"âŒ ä¸‹è¼‰ {symbol} æ•¸æ“šå¤±æ•—: {str(e)}")
            raise
            
    def read_stock_data(self, symbol: str) -> pd.DataFrame:
        """å¾CSVè®€å–è‚¡ç¥¨æ•¸æ“š"""
        try:
            file_path = self.get_stock_file_path(symbol)
            data = pd.read_csv(file_path)
            
            # å°‡æ—¥æœŸåˆ—è½‰æ›ç‚ºdatetime
            data['date'] = pd.to_datetime(data['date'])
            
            self.logger.info(f"âœ… å¾CSVè®€å– {symbol} æ•¸æ“š: {len(data)} å¤©")
            return data
            
        except Exception as e:
            self.logger.error(f"âŒ è®€å– {symbol} æ•¸æ“šå¤±æ•—: {str(e)}")
            raise

    @staticmethod
    def get_northbound_data(symbol: str = "2800.HK", 
                           start_date: Optional[str] = None, 
                           end_date: Optional[str] = None) -> Optional[pd.DataFrame]:
        """
        ç²å–åŒ—æ°´å—ä¸‹æ•¸æ“š
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç¢¼
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            
        Returns:
            åŒ—æ°´æ•¸æ“šDataFrame
        """
        try:
            logger.info(f"ğŸŒŠ æ­£åœ¨ç²å– {symbol} çš„åŒ—æ°´æ•¸æ“š...")
            
            # è¨­ç½®é»˜èªæ—¥æœŸç¯„åœ
            if not end_date:
                end_date = datetime.now().strftime('%Y-%m-%d')
            if not start_date:
                start_date = (datetime.now() - timedelta(days=180)).strftime('%Y-%m-%d')
            
            # é€™è£¡å¯ä»¥å¯¦ç¾åŒ—æ°´æ•¸æ“šçš„APIèª¿ç”¨
            # ç”±æ–¼å¯¦éš›APIå¯èƒ½éœ€è¦æˆæ¬Šï¼Œé€™è£¡æä¾›æ¨¡æ“¬æ•¸æ“šçµæ§‹
            
            # å‰µå»ºæ¨¡æ“¬åŒ—æ°´æ•¸æ“š
            date_range = pd.date_range(start=start_date, end=end_date, freq='D')
            northbound_data = pd.DataFrame({
                'Date': date_range,
                'Northbound_Net_Buy': np.random.normal(100000, 50000, len(date_range)),
                'Northbound_Buy': np.random.normal(500000, 100000, len(date_range)),
                'Northbound_Sell': np.random.normal(400000, 80000, len(date_range)),
                'Northbound_Holdings': np.random.normal(10000000, 1000000, len(date_range))
            })
            
            northbound_data.set_index('Date', inplace=True)
            
            # æ·»åŠ  north_flow åˆ—ï¼ˆä½¿ç”¨æ·¨è²·å…¥é‡‘é¡é™¤ä»¥æŒå€‰é‡‘é¡çš„æ¯”ä¾‹ï¼‰
            northbound_data['north_flow'] = northbound_data['Northbound_Net_Buy'] / northbound_data['Northbound_Holdings']
            
            logger.info(f"âœ… æˆåŠŸç²å– {len(northbound_data)} å¤©çš„åŒ—æ°´æ•¸æ“š")
            return northbound_data
            
        except Exception as e:
            logger.error(f"âŒ ç²å–åŒ—æ°´æ•¸æ“šå¤±æ•—: {e}")
            return None
    
    @staticmethod
    def _clean_data(data: Union[pd.DataFrame, pd.Series]) -> pd.DataFrame:
        """
        æ¸…ç†æ•¸æ“š
        
        Args:
            data: åŸå§‹æ•¸æ“š
            
        Returns:
            æ¸…ç†å¾Œçš„æ•¸æ“š
        """
        try:
            # ç¢ºä¿è¼¸å…¥æ˜¯ DataFrame
            if not isinstance(data, pd.DataFrame):
                if isinstance(data, pd.Series):
                    data = data.to_frame()
                else:
                    return pd.DataFrame()  # è¿”å›ç©ºçš„ DataFrame
            
            # ç§»é™¤ç©ºå€¼
            cleaned_data = data.dropna()
            
            # ç¢ºä¿æ•¸æ“šé¡å‹æ­£ç¢º
            numeric_columns = ['Open', 'High', 'Low', 'Close', 'Volume']
            for col in numeric_columns:
                if col in cleaned_data.columns:
                    cleaned_data[col] = pd.to_numeric(cleaned_data[col], errors='coerce')
            
            # ç§»é™¤ç•°å¸¸å€¼ï¼ˆåƒ¹æ ¼ç‚º0æˆ–è² æ•¸ï¼‰
            if 'Close' in cleaned_data.columns:
                cleaned_data = cleaned_data[cleaned_data['Close'] > 0]
            
            # æ’åº
            cleaned_data = cleaned_data.sort_index()
            
            return cast(pd.DataFrame, cleaned_data)
            
        except Exception as e:
            logger.error(f"æ•¸æ“šæ¸…ç†å¤±æ•—: {e}")
            return pd.DataFrame() if not isinstance(data, pd.DataFrame) else data
    
    @staticmethod
    def _merge_northbound_data(stock_data: pd.DataFrame, 
                              northbound_data: pd.DataFrame) -> pd.DataFrame:
        """
        åˆä½µåŒ—æ°´æ•¸æ“š
        
        Args:
            stock_data: è‚¡ç¥¨æ•¸æ“š
            northbound_data: åŒ—æ°´æ•¸æ“š
            
        Returns:
            åˆä½µå¾Œçš„æ•¸æ“š
        """
        try:
            # ç¢ºä¿ç´¢å¼•æ ¼å¼ä¸€è‡´
            stock_data.index = pd.to_datetime(stock_data.index)
            northbound_data.index = pd.to_datetime(northbound_data.index)
            
            # åˆä½µæ•¸æ“š
            merged_data = stock_data.join(northbound_data, how='left')
            
            # å¡«å……ç¼ºå¤±å€¼
            northbound_columns = ['Northbound_Net_Buy', 'Northbound_Buy', 
                                'Northbound_Sell', 'Northbound_Holdings']
            for col in northbound_columns:
                if col in merged_data.columns:
                    merged_data[col] = merged_data[col].fillna(0)
            
            return merged_data
            
        except Exception as e:
            logger.error(f"æ•¸æ“šåˆä½µå¤±æ•—: {e}")
            return stock_data

    def get_yahoo_finance_data(self, symbol: str, start_date: str, end_date: str, retries: int = 3) -> pd.DataFrame:
        """
        ç›´æ¥å¾Yahoo Finance APIç²å–æ•¸æ“šï¼Œèˆ‡ main.py çš„ get_stock_data_direct ä¸€è‡´
        Args:
            symbol: è‚¡ç¥¨ä»£ç¢¼ï¼ˆå¦‚ 2800.HKï¼‰
            start_date: é–‹å§‹æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰
            end_date: çµæŸæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰
            retries: é‡è©¦æ¬¡æ•¸
        Returns:
            pd.DataFrame æˆ– None
        """
        import requests
        import time
        import pandas as pd
        from datetime import datetime
        import pytz
        hk_tz = pytz.timezone('Asia/Hong_Kong')
        try:
            start_dt = datetime.strptime(start_date, '%Y-%m-%d').replace(tzinfo=hk_tz)
            end_dt = datetime.strptime(end_date, '%Y-%m-%d').replace(tzinfo=hk_tz)
        except Exception as e:
            self.logger.error(f"âŒ æ—¥æœŸæ ¼å¼éŒ¯èª¤: {e}")
            return None
        base_url = "https://query1.finance.yahoo.com/v8/finance/chart/"
        start_timestamp = int(start_dt.timestamp())
        end_timestamp = int(end_dt.timestamp())
        url = f"{base_url}{symbol}?period1={start_timestamp}&period2={end_timestamp}&interval=1d"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        for attempt in range(retries):
            try:
                response = requests.get(url, headers=headers)
                response.raise_for_status()
                data = response.json()
                if 'chart' in data and 'result' in data['chart'] and data['chart']['result']:
                    result = data['chart']['result'][0]
                    timestamps = result['timestamp']
                    quotes = result['indicators']['quote'][0]
                    df = pd.DataFrame({
                        'open': quotes.get('open', []),
                        'high': quotes.get('high', []),
                        'low': quotes.get('low', []),
                        'close': quotes.get('close', []),
                        'volume': quotes.get('volume', [])
                    }, index=pd.to_datetime(timestamps, unit='s'))
                    return df
                return None
            except requests.exceptions.RequestException as e:
                if attempt < retries - 1:
                    self.logger.warning(f"è«‹æ±‚å¤±æ•—ï¼Œæ­£åœ¨é‡è©¦... ({attempt + 1}/{retries})")
                    time.sleep(2 ** attempt)
                else:
                    self.logger.error(f"ç„¡æ³•ç²å–æ•¸æ“š: {str(e)}")
                    return None
            except Exception as e:
                self.logger.error(f"è™•ç†æ•¸æ“šæ™‚å‡ºéŒ¯: {str(e)}")
                return None
    def fetch_data(self, symbol: str, start_date: str, end_date: str) -> pd.DataFrame:
        """
        é€šç”¨æ•¸æ“šç²å–æ¥å£ï¼Œä¾› UnifiedStrategyOptimizer ä½¿ç”¨ã€‚
        å…§éƒ¨èª¿ç”¨ get_yahoo_finance_dataï¼Œä¸¦è‡ªå‹•æ¨™æº–åŒ–æ¬„ä½ã€‚
        """
        df = self.get_yahoo_finance_data(symbol, start_date, end_date)
        if df is None or df.empty:
            self.logger.error(f"âŒ fetch_data: ç„¡æ³•ç²å– {symbol} æ•¸æ“šï¼Œæ—¥æœŸ: {start_date}~{end_date}")
            return None
        # æ¨™æº–åŒ–æ¬„ä½åç¨±
        df = df.rename(columns={
            'Open': 'open', 'High': 'high', 'Low': 'low', 'Close': 'close', 'Volume': 'volume',
            'open': 'open', 'high': 'high', 'low': 'low', 'close': 'close', 'volume': 'volume'
        })
        # å°‡ index è½‰ç‚º date æ¬„ä½
        if 'date' not in df.columns:
            df = df.reset_index().rename(columns={'index': 'date'})
        # ç¢ºä¿æ‰€æœ‰æ¬„ä½å°å¯«
        df.columns = [str(col).lower() for col in df.columns]
        # æ—¥èªŒï¼šè¼¸å‡ºæ¬„ä½ã€shapeã€å‰å¹¾è¡Œ
        self.logger.info(f"fetch_data: {symbol} æ•¸æ“š shape={df.shape}, columns={list(df.columns)}")
        self.logger.info(f"fetch_data: {symbol} head={df.head(3)}")
        # åªæª¢æŸ¥ close æ¬„ä½ç©ºå€¼ï¼Œå…è¨±å…¶ä»–æ¬„ä½æœ‰å°é‡ç©ºå€¼
        if df['close'].isnull().sum() > 0:
            self.logger.warning(f"fetch_data: {symbol} æœ‰ {df['close'].isnull().sum()} å€‹ close ç©ºå€¼ï¼Œå°‡ç§»é™¤")
            df = df.dropna(subset=['close'])
        if df.empty:
            self.logger.error(f"âŒ fetch_data: {symbol} è™•ç†å¾Œæ•¸æ“šç‚ºç©ºï¼Œæ”¾æ£„")
            return None
        return df


class TechnicalIndicators:
    """æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å™¨"""
    
    @staticmethod
    def calculate_rsi(close_prices: Union[pd.Series, pd.DataFrame], period: int = 14) -> pd.Series:
        """
        è¨ˆç®—RSIæŒ‡æ¨™
        
        Args:
            close_prices: æ”¶ç›¤åƒ¹åºåˆ—æˆ–DataFrame
            period: è¨ˆç®—é€±æœŸ
            
        Returns:
            RSIå€¼åºåˆ—
        """
        try:
            if isinstance(close_prices, pd.DataFrame):
                close_prices = close_prices['Close']
            
            if len(close_prices) < period:
                return pd.Series(index=close_prices.index, dtype=float)
            
            delta = close_prices.diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
            
            rs = gain / loss
            rsi = 100 - (100 / (1 + rs))
            return pd.Series(rsi, index=close_prices.index)
            
        except Exception as e:
            logger.error(f"RSIè¨ˆç®—å¤±æ•—: {e}")
            return pd.Series(index=close_prices.index, dtype=float)
    
    @staticmethod
    def calculate_macd(close_prices: Union[pd.Series, pd.DataFrame], fast: int = 12, 
                      slow: int = 26, signal: int = 9) -> Dict[str, pd.Series]:
        """
        è¨ˆç®—MACDæŒ‡æ¨™
        
        Args:
            close_prices: æ”¶ç›¤åƒ¹åºåˆ—æˆ–DataFrame
            fast: å¿«ç·šé€±æœŸ
            slow: æ…¢ç·šé€±æœŸ
            signal: ä¿¡è™Ÿç·šé€±æœŸ
            
        Returns:
            åŒ…å«MACDç·šã€ä¿¡è™Ÿç·šå’ŒæŸ±ç‹€åœ–çš„å­—å…¸
        """
        try:
            if isinstance(close_prices, pd.DataFrame):
                close_prices = close_prices['Close']
            
            exp1 = close_prices.ewm(span=fast, adjust=False).mean()
            exp2 = close_prices.ewm(span=slow, adjust=False).mean()
            macd = exp1 - exp2
            signal_line = macd.ewm(span=signal, adjust=False).mean()
            histogram = macd - signal_line
            
            return {
                'MACD': macd,
                'Signal': signal_line,
                'Histogram': histogram
            }
            
        except Exception as e:
            logger.error(f"MACDè¨ˆç®—å¤±æ•—: {e}")
            empty_series = pd.Series(index=close_prices.index, dtype=float)
            return {
                'MACD': empty_series,
                'Signal': empty_series,
                'Histogram': empty_series
            }
    
    @staticmethod
    def calculate_bollinger_bands(close_prices: Union[pd.Series, pd.DataFrame], period: int = 20, 
                                std_dev: float = 2.0) -> Dict[str, pd.Series]:
        """
        è¨ˆç®—å¸ƒæ—é€šé“
        
        Args:
            close_prices: æ”¶ç›¤åƒ¹åºåˆ—æˆ–DataFrame
            period: è¨ˆç®—é€±æœŸ
            std_dev: æ¨™æº–å·®å€æ•¸
            
        Returns:
            åŒ…å«ä¸­è»Œã€ä¸Šè»Œå’Œä¸‹è»Œçš„å­—å…¸
        """
        try:
            if isinstance(close_prices, pd.DataFrame):
                close_prices = close_prices['Close']
            
            middle = close_prices.rolling(window=period).mean()
            std = close_prices.rolling(window=period).std()
            upper = middle + (std * std_dev)
            lower = middle - (std * std_dev)
            
            return {
                'Middle': middle,
                'Upper': upper,
                'Lower': lower
            }
            
        except Exception as e:
            logger.error(f"å¸ƒæ—é€šé“è¨ˆç®—å¤±æ•—: {e}")
            empty_series = pd.Series(index=close_prices.index, dtype=float)
            return {
                'Middle': empty_series,
                'Upper': empty_series,
                'Lower': empty_series
            }
    
    @staticmethod
    def calculate_moving_averages(close_prices: Union[pd.Series, pd.DataFrame], 
                                periods: List[int] = [5, 10, 20, 50]) -> Dict[str, pd.Series]:
        """
        è¨ˆç®—ç§»å‹•å¹³å‡ç·š
        
        Args:
            close_prices: æ”¶ç›¤åƒ¹åºåˆ—æˆ–DataFrame
            periods: è¨ˆç®—é€±æœŸåˆ—è¡¨
            
        Returns:
            åŒ…å«å„é€±æœŸç§»å‹•å¹³å‡ç·šçš„å­—å…¸
        """
        try:
            if isinstance(close_prices, pd.DataFrame):
                close_prices = close_prices['Close']
            
            ma_dict = {}
            for period in periods:
                ma = close_prices.rolling(window=period).mean()
                ma_dict[f'MA{period}'] = ma
            
            return ma_dict
            
        except Exception as e:
            logger.error(f"ç§»å‹•å¹³å‡ç·šè¨ˆç®—å¤±æ•—: {e}")
            empty_series = pd.Series(index=close_prices.index, dtype=float)
            return {f'MA{period}': empty_series.copy() for period in periods}
    
    @staticmethod
    def calculate_all_indicators(data: pd.DataFrame) -> pd.DataFrame:
        """
        è¨ˆç®—æ‰€æœ‰æŠ€è¡“æŒ‡æ¨™
        
        Args:
            data: è‚¡ç¥¨æ•¸æ“šDataFrame
            
        Returns:
            æ·»åŠ äº†æŠ€è¡“æŒ‡æ¨™çš„DataFrame
        """
        try:
            result_data = data.copy()
            
            # è¨ˆç®—RSI
            result_data['RSI'] = TechnicalIndicators.calculate_rsi(result_data['Close'])
            
            # è¨ˆç®—MACD
            macd_data = TechnicalIndicators.calculate_macd(result_data['Close'])
            result_data['MACD'] = macd_data['MACD']
            result_data['MACD_Signal'] = macd_data['Signal']
            result_data['MACD_Histogram'] = macd_data['Histogram']
            
            # è¨ˆç®—å¸ƒæ—é€šé“
            bb_data = TechnicalIndicators.calculate_bollinger_bands(result_data['Close'])
            result_data['BB_Middle'] = bb_data['Middle']
            result_data['BB_Upper'] = bb_data['Upper']
            result_data['BB_Lower'] = bb_data['Lower']
            
            # è¨ˆç®—ç§»å‹•å¹³å‡ç·š
            ma_data = TechnicalIndicators.calculate_moving_averages(result_data['Close'])
            for ma_name, ma_values in ma_data.items():
                result_data[ma_name] = ma_values
            
            return result_data
            
        except Exception as e:
            logger.error(f"æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å¤±æ•—: {e}")
            return data

class DataValidator:
    """æ•¸æ“šé©—è­‰å™¨"""
    
    @staticmethod
    def validate_data_quality(data: pd.DataFrame) -> Dict[str, Any]:
        """
        é©—è­‰æ•¸æ“šè³ªé‡
        
        Args:
            data: å¾…é©—è­‰çš„DataFrame
            
        Returns:
            é©—è­‰çµæœå­—å…¸
        """
        try:
            # ç²å–æ—¥æœŸç¯„åœ
            start_date = None
            end_date = None
            if not data.empty and isinstance(data.index, pd.DatetimeIndex):
                start_date = format_date_safely(data.index.min())
                end_date = format_date_safely(data.index.max())
            
            validation_results = {
                'missing_values': data.isnull().sum().to_dict(),
                'data_types': {str(k): str(v) for k, v in data.dtypes.to_dict().items()},
                'row_count': len(data),
                'column_count': len(data.columns),
                'date_range': {
                    'start': start_date,
                    'end': end_date
                }
            }
            
            return validation_results
            
        except Exception as e:
            logger.error(f"æ•¸æ“šé©—è­‰å¤±æ•—: {e}")
            return {
                'error': str(e),
                'status': 'failed'
            } 