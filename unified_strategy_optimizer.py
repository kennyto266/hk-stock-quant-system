#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
çµ±ä¸€ç­–ç•¥å„ªåŒ–å™¨ï¼Œæ”¯æ´å¤šç¨®å„ªåŒ–æ¨¡å¼ï¼ˆç¶²æ ¼ã€éš¨æ©Ÿã€éºå‚³ã€æš´åŠ›ã€å¤šé€²ç¨‹ç­‰ï¼‰
"""

import pandas as pd
import numpy as np
import random
from typing import Dict, List, Any, Tuple, Callable, Optional, Union
from datetime import datetime
import itertools
from multiprocessing import Pool, cpu_count
from functools import partial
from tqdm import tqdm
import logging
import gc
import psutil
import warnings
from data_handler import DataFetcher
import strategies

warnings.filterwarnings('ignore')
logger = logging.getLogger(__name__)

class UnifiedStrategyOptimizer:
    """
    çµ±ä¸€ç­–ç•¥å„ªåŒ–å™¨ï¼Œæ”¯æ´å¤šç¨®å„ªåŒ–æ¨¡å¼ï¼ˆç¶²æ ¼ã€éš¨æ©Ÿã€éºå‚³ã€æš´åŠ›ã€å¤šé€²ç¨‹ç­‰ï¼‰
    """
    def __init__(self, symbol: str, start_date: str, end_date: Optional[str] = None):
        self.symbol = symbol
        self.start_date = start_date
        self.end_date = end_date if end_date is not None else datetime.now().strftime('%Y-%m-%d')
        self.data: Optional[pd.DataFrame] = None
        self.train_data: Optional[pd.DataFrame] = None
        self.validation_data: Optional[pd.DataFrame] = None
        self.best_params: Dict = {}
        self.use_cross_validation = False  # é—œé–‰äº¤å‰é©—è­‰
        self.train_ratio = 0.7  # ä½¿ç”¨70%æ•¸æ“šä½œç‚ºè¨“ç·´é›†
        self.max_processes = min(32, cpu_count())
        self.signals: Optional[pd.Series] = None
        self._setup_logging()
        
    def _load_data(self) -> Optional[pd.DataFrame]:
        """è¼‰å…¥æ•¸æ“š"""
        try:
            fetcher = DataFetcher()
            data = fetcher.fetch_data(self.symbol, self.start_date, self.end_date)
            if isinstance(data, pd.DataFrame):
                logger.info(f"âœ… æˆåŠŸè¼‰å…¥ {len(data)} å¤©çš„æ•¸æ“š")
                return data
            else:
                logger.error("âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—")
                return None
        except Exception as e:
            logger.error(f"âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—: {str(e)}")
            return None
            
    def _generate_param_grid(self) -> List[Dict]:
        """ç”Ÿæˆåƒæ•¸ç¶²æ ¼"""
        param_grid = []
        
        # RSI ç­–ç•¥åƒæ•¸
        for period in range(5, 301, 5):  # 5-300
            for overbought in range(50, 91, 5):  # 50-90
                for oversold in range(10, 51, 5):  # 10-50
                    if oversold < overbought:
                        param_grid.append({
                            'strategy_type': 'RSI',
                            'period': period,
                            'overbought': overbought,
                            'oversold': oversold
                        })
        
        # MACD ç­–ç•¥åƒæ•¸
        for fast in range(5, 21):  # 5-20
            for slow in range(15, 41):  # 15-40
                for signal in range(5, 16):  # 5-15
                    if fast < slow:
                        param_grid.append({
                            'strategy_type': 'MACD',
                            'fast_period': fast,
                            'slow_period': slow,
                            'signal_period': signal
                        })
        
        # å¸ƒæ—é€šé“ç­–ç•¥åƒæ•¸
        for period in range(10, 51, 2):  # 10-50
            for std_dev in np.arange(1.5, 3.1, 0.1):  # 1.5-3.0
                param_grid.append({
                    'strategy_type': 'Bollinger',
                    'period': period,
                    'std_dev': float(std_dev)
                })
                
        return param_grid
        
    def _create_strategy(self, params: Dict) -> Any:
        """æ ¹æ“šåƒæ•¸å‰µå»ºç­–ç•¥å¯¦ä¾‹"""
        strategy_type = params.get('strategy_type', 'RSI')
        
        if strategy_type == 'RSI':
            return strategies.RSIStrategy(
                period=params.get('period', 14),
                overbought=params.get('overbought', 70),
                oversold=params.get('oversold', 30)
            )
        elif strategy_type == 'MACD':
            return strategies.MACDStrategy(
                fast_period=params.get('fast_period', 12),
                slow_period=params.get('slow_period', 26),
                signal_period=params.get('signal_period', 9)
            )
        elif strategy_type == 'Bollinger':
            return strategies.BollingerStrategy(
                period=params.get('period', 20),
                std_dev=params.get('std_dev', 2.0)
            )
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„ç­–ç•¥é¡å‹: {strategy_type}")
            
    def optimize(self) -> Optional[Dict]:
        """å„ªåŒ–ç­–ç•¥åƒæ•¸"""
        logger.info("ğŸ”„ é–‹å§‹å„ªåŒ–ç­–ç•¥åƒæ•¸...")
        
        # è¼‰å…¥æ•¸æ“š
        self.data = self._load_data()
        if not isinstance(self.data, pd.DataFrame) or self.data.empty:
            logger.error("âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—")
            return None
            
        # åˆ†å‰²è¨“ç·´é›†å’Œé©—è­‰é›†
        train_size = int(len(self.data) * self.train_ratio)
        self.train_data = self.data.iloc[:train_size].copy()
        self.validation_data = self.data.iloc[train_size:].copy()
        
        if isinstance(self.train_data, pd.DataFrame) and isinstance(self.validation_data, pd.DataFrame):
            logger.info(f"ğŸ“ˆ è¨“ç·´é›†å¤§å°: {len(self.train_data)} å¤©")
            logger.info(f"ğŸ“Š é©—è­‰é›†å¤§å°: {len(self.validation_data)} å¤©")
        else:
            logger.error("âŒ æ•¸æ“šåˆ†å‰²å¤±æ•—")
            return None
        
        # ç”Ÿæˆåƒæ•¸ç¶²æ ¼
        param_combinations = self._generate_param_grid()
        if not param_combinations:
            logger.error("âŒ ç„¡æœ‰æ•ˆåƒæ•¸çµ„åˆ")
            return None
            
        logger.info(f"ğŸ” ç¸½åƒæ•¸çµ„åˆæ•¸: {len(param_combinations)}")
        
        # ä½¿ç”¨å¤šé€²ç¨‹å„ªåŒ–
        with Pool(processes=self.max_processes) as pool:
            eval_args = [(params, self.train_data, self.validation_data) 
                        for params in param_combinations]
            results = list(tqdm(pool.imap(self._evaluate_params, eval_args),
                              total=len(param_combinations),
                              desc="åƒæ•¸å„ªåŒ–é€²åº¦"))
        
        # æ‰¾å‡ºæœ€ä½³åƒæ•¸
        if results:
            best_result = max(results, key=lambda x: x['metrics']['sharpe_ratio'])
            self.best_params = best_result['params']
            
            # ä½¿ç”¨æœ€ä½³åƒæ•¸ç”Ÿæˆä¿¡è™Ÿ
            strategy = self._create_strategy(self.best_params)
            strategy.fit(self.data)
            self.signals = strategy.signals
            
            logger.info(f"âœ… æœ€ä½³åƒæ•¸: {self.best_params}")
            logger.info(f"ğŸ“Š æœ€ä½³å¤æ™®æ¯”ç‡: {best_result['metrics']['sharpe_ratio']:.2f}")
            
            return self.best_params
        else:
            logger.error("âŒ ç„¡æœ‰æ•ˆå„ªåŒ–çµæœ")
            return None

    def _evaluate_params(self, args: Tuple[Dict, pd.DataFrame, pd.DataFrame]) -> Dict:
        """è©•ä¼°å–®å€‹åƒæ•¸çµ„åˆ"""
        params, train_data, validation_data = args
        
        if not isinstance(train_data, pd.DataFrame) or not isinstance(validation_data, pd.DataFrame):
            return {
                'params': params,
                'metrics': {'sharpe_ratio': float('-inf')}
            }
        
        try:
            # åœ¨è¨“ç·´é›†ä¸Šè¨“ç·´ç­–ç•¥
            strategy = self._create_strategy(params)
            strategy.fit(train_data)
            
            # åœ¨é©—è­‰é›†ä¸Šè©•ä¼°
            metrics = strategy.evaluate(validation_data)
            
            return {
                'params': params,
                'metrics': metrics
            }
        except Exception as e:
            logger.error(f"âŒ åƒæ•¸è©•ä¼°å¤±æ•—: {params} - {str(e)}")
            return {
                'params': params,
                'metrics': {'sharpe_ratio': float('-inf')}
            }

    def _setup_logging(self):
        """è¨­ç½®æ—¥èªŒè¨˜éŒ„"""
        logger.setLevel(logging.INFO)
        if not logger.handlers:
            handler = logging.StreamHandler()
            handler.setFormatter(logging.Formatter(
                '%(asctime)s - %(levelname)s - %(message)s'
            ))
            logger.addHandler(handler)

    def evaluate_strategy(self, strategy_class: Callable, params: Dict, data: pd.DataFrame) -> Dict:
        """è©•ä¼°å–®å€‹ç­–ç•¥çš„æ€§èƒ½ï¼ŒåŒ…å«æ›´å…¨é¢çš„ç¸¾æ•ˆæŒ‡æ¨™"""
        try:
            strategy = strategy_class(**params)
            signals = strategy.generate_signals(data)
            if signals.empty or 'signal' not in signals.columns:
                return {}
            
            # è¨ˆç®—äº¤æ˜“çµ±è¨ˆ
            nonzero_count = int((signals['signal'] != 0).sum())
            if nonzero_count == 0:  # å¦‚æœæ²’æœ‰äº¤æ˜“ä¿¡è™Ÿï¼Œè¿”å›ç©ºçµæœ
                return {}
                
            signals['position'] = signals['signal'].replace(0, np.nan).fillna(method='ffill').fillna(0)
            signals['returns'] = data['Close'].pct_change().fillna(0)
            signals['strategy_returns'] = signals['position'].shift(1) * signals['returns']
            
            # ç§»é™¤é¦–å€‹äº¤æ˜“æ—¥çš„æ”¶ç›Šï¼ˆå› ç‚ºæ²’æœ‰å‰ä¸€å¤©çš„å€‰ä½ï¼‰
            signals.loc[signals.index[0], 'strategy_returns'] = 0
            
            signals['equity'] = (1 + signals['strategy_returns']).cumprod()
            
            # è¨ˆç®—åŸºç¤ç¸¾æ•ˆæŒ‡æ¨™
            total_return = signals['equity'].iloc[-1] - 1
            annual_return = (1 + total_return) ** (252 / len(signals)) - 1
            daily_returns = signals['strategy_returns']
            volatility = daily_returns.std() * np.sqrt(252)
            
            # è¨ˆç®—å¤æ™®æ¯”ç‡ï¼ˆå¦‚æœæ³¢å‹•ç‡ç‚º0ï¼Œå‰‡è¿”å›0ï¼‰
            risk_free_rate = 0.02  # å‡è¨­ç„¡é¢¨éšªåˆ©ç‡ç‚º2%
            excess_returns = annual_return - risk_free_rate
            sharpe_ratio = excess_returns / volatility if volatility > 0 else 0
            
            # è¨ˆç®—ç´¢æè«¾æ¯”ç‡
            downside_returns = daily_returns[daily_returns < 0]
            downside_volatility = downside_returns.std() * np.sqrt(252) if not downside_returns.empty else 0
            sortino_ratio = excess_returns / downside_volatility if downside_volatility > 0 else 0
            
            # è¨ˆç®—æœ€å¤§å›æ’¤åŠå…¶æŒçºŒæ™‚é–“
            rolling_max = signals['equity'].expanding().max()
            drawdowns = signals['equity'] / rolling_max - 1
            max_drawdown = drawdowns.min()
            
            # è¨ˆç®—æœ€å¤§å›æ’¤æŒçºŒæ™‚é–“
            drawdown_periods = pd.DataFrame(index=signals.index)
            drawdown_periods['drawdown'] = drawdowns
            drawdown_periods['is_drawdown'] = drawdown_periods['drawdown'] < 0
            drawdown_periods['drawdown_group'] = (drawdown_periods['is_drawdown'] != drawdown_periods['is_drawdown'].shift()).cumsum()
            drawdown_durations = drawdown_periods[drawdown_periods['is_drawdown']].groupby('drawdown_group').size()
            max_drawdown_duration = drawdown_durations.max() if not drawdown_durations.empty else 0
            
            # è¨ˆç®—äº¤æ˜“çµ±è¨ˆ
            trading_days = signals[signals['strategy_returns'] != 0]
            win_rate = (trading_days['strategy_returns'] > 0).mean() * 100 if not trading_days.empty else 0
            
            # è¨ˆç®—å¹³å‡ç²åˆ©å’Œè™§æ
            avg_profit = trading_days[trading_days['strategy_returns'] > 0]['strategy_returns'].mean() if not trading_days.empty else 0
            avg_loss = trading_days[trading_days['strategy_returns'] < 0]['strategy_returns'].mean() if not trading_days.empty else 0
            profit_loss_ratio = abs(avg_profit / avg_loss) if avg_loss != 0 else 0
            
            # è¨ˆç®—æŒå€‰æ™‚é–“çµ±è¨ˆ
            position_changes = signals['position'].diff().fillna(0)
            trade_starts = position_changes != 0
            holding_periods = []
            current_period = 0
            
            for i in range(len(signals)):
                if trade_starts.iloc[i]:
                    if current_period > 0:
                        holding_periods.append(current_period)
                    current_period = 1
                elif signals['position'].iloc[i] != 0:
                    current_period += 1
            
            if current_period > 0:
                holding_periods.append(current_period)
            
            avg_holding_period = np.mean(holding_periods) if holding_periods else 0
            
            # æ¸…ç†è¨˜æ†¶é«”
            del signals, drawdown_periods, trading_days
            gc.collect()
            
            return {
                'sharpe_ratio': sharpe_ratio,
                'sortino_ratio': sortino_ratio,
                'annual_return': annual_return * 100,  # è½‰æ›ç‚ºç™¾åˆ†æ¯”
                'max_drawdown': max_drawdown * 100,  # è½‰æ›ç‚ºç™¾åˆ†æ¯”
                'max_drawdown_duration': max_drawdown_duration,
                'volatility': volatility * 100,  # è½‰æ›ç‚ºç™¾åˆ†æ¯”
                'win_rate': win_rate,
                'profit_loss_ratio': profit_loss_ratio,
                'avg_holding_period': avg_holding_period,
                'trade_count': nonzero_count,
                'avg_profit': avg_profit * 100,  # è½‰æ›ç‚ºç™¾åˆ†æ¯”
                'avg_loss': avg_loss * 100  # è½‰æ›ç‚ºç™¾åˆ†æ¯”
            }
        except Exception as e:
            logger.error(f"Strategy evaluation failed: {e}")
            return {}

    def _evaluate_grid_params(self, args: Tuple[Callable, Dict, pd.DataFrame]) -> Optional[Tuple[Dict, Dict]]:
        """è©•ä¼°å–®å€‹ç¶²æ ¼æœç´¢åƒæ•¸çµ„åˆ"""
        strategy_class, params, data = args
        metrics = self.evaluate_strategy(strategy_class, params, data)
        if metrics and 'sharpe_ratio' in metrics and metrics['trade_count'] > 0:
            return params, metrics
        return None

    def grid_search(self, strategy_class, param_grid: Dict) -> Dict:
        """
        ä½¿ç”¨å¤šé€²ç¨‹é€²è¡Œç¶²æ ¼æœç´¢ï¼ŒåŒ…å«äº¤å‰é©—è­‰
        
        Args:
            strategy_class: ç­–ç•¥é¡
            param_grid: åƒæ•¸ç¶²æ ¼ï¼Œæ ¼å¼ç‚º {'param_name': [param_values]}
        """
        # é©—è­‰åƒæ•¸ç¯„åœ
        self._validate_param_grid(param_grid)
        
        param_names = list(param_grid.keys())
        param_values = list(param_grid.values())
        param_combinations = list(itertools.product(*param_values))
        
        logger.info(f"é–‹å§‹ç¶²æ ¼æœç´¢ï¼Œå…± {len(param_combinations)} çµ„åƒæ•¸çµ„åˆ")
        
        # æº–å‚™äº¤å‰é©—è­‰
        n_splits = 5  # 5æŠ˜äº¤å‰é©—è­‰
        data_length = len(self.train_data)
        fold_size = data_length // n_splits
        
        all_results = []
        for fold in range(n_splits):
            logger.info(f"é–‹å§‹ç¬¬ {fold + 1} æŠ˜äº¤å‰é©—è­‰")
            
            # æº–å‚™è¨“ç·´å’Œé©—è­‰æ•¸æ“š
            val_start = fold * fold_size
            val_end = val_start + fold_size
            if fold == n_splits - 1:  # æœ€å¾Œä¸€æŠ˜ä½¿ç”¨å‰©é¤˜æ‰€æœ‰æ•¸æ“š
                val_end = data_length
            
            train_data = pd.concat([
                self.train_data.iloc[:val_start],
                self.train_data.iloc[val_end:]
            ])
            val_data = self.train_data.iloc[val_start:val_end]
            
            # æº–å‚™åƒæ•¸çµ„åˆ
            eval_args = [(strategy_class, dict(zip(param_names, params)), train_data) 
                        for params in param_combinations]
            
            # ä½¿ç”¨å¤šé€²ç¨‹é€²è¡Œè©•ä¼°
            with Pool(processes=self.max_processes) as pool:
                fold_results = list(tqdm(pool.imap(self._evaluate_grid_params, eval_args), 
                                      total=len(param_combinations), 
                                      desc=f"ç¬¬ {fold + 1} æŠ˜æœç´¢é€²åº¦"))
            
            # éæ¿¾æœ‰æ•ˆçµæœä¸¦è¨ˆç®—é©—è­‰é›†ç¸¾æ•ˆ
            valid_results = []
            for result in fold_results:
                if result is not None:
                    params, train_metrics = result
                    val_metrics = self.evaluate_strategy(strategy_class, params, val_data)
                    if val_metrics:  # åªä¿ç•™åœ¨é©—è­‰é›†ä¸Šä¹Ÿæœ‰æ•ˆçš„çµæœ
                        valid_results.append({
                            'params': params,
                            'train_metrics': train_metrics,
                            'val_metrics': val_metrics,
                            'fold': fold
                        })
            
            all_results.extend(valid_results)
            
            # æ¸…ç†è¨˜æ†¶é«”
            del train_data, val_data, fold_results, valid_results
            gc.collect()
        
        if all_results:
            # æ ¹æ“šæ‰€æœ‰æŠ˜çš„å¹³å‡ç¸¾æ•ˆé€²è¡Œæ’åº
            def avg_score(result):
                train_sharpe = result['train_metrics']['sharpe_ratio']
                val_sharpe = result['val_metrics']['sharpe_ratio']
                train_sortino = result['train_metrics']['sortino_ratio']
                val_sortino = result['val_metrics']['sortino_ratio']
                train_trades = result['train_metrics']['trade_count']
                val_trades = result['val_metrics']['trade_count']
                
                # ç¶œåˆè€ƒæ…®å¤æ™®æ¯”ç‡ã€ç´¢æè«¾æ¯”ç‡å’Œäº¤æ˜“æ¬¡æ•¸
                train_score = (train_sharpe + train_sortino) * (1 + np.log1p(train_trades) / 10)
                val_score = (val_sharpe + val_sortino) * (1 + np.log1p(val_trades) / 10)
                
                # å¦‚æœä»»ä¸€æŒ‡æ¨™ç‚ºè² ï¼Œå‰‡åˆ†æ•¸ç‚ºè² ç„¡çª®
                if train_sharpe <= 0 or val_sharpe <= 0:
                    return float('-inf')
                
                # è¿”å›è¨“ç·´é›†å’Œé©—è­‰é›†çš„å¹³å‡åˆ†æ•¸
                return (train_score + val_score) / 2
            
            # æ‰¾å‡ºæœ€ä½³åƒæ•¸çµ„åˆ
            best_result = max(all_results, key=avg_score)
            best_params = best_result['params']
            
            # åœ¨å®Œæ•´é©—è­‰é›†ä¸Šé€²è¡Œæœ€çµ‚è©•ä¼°
            final_validation_metrics = self.evaluate_strategy(strategy_class, best_params, self.validation_data)
            
            # è¨ˆç®—åƒæ•¸ç©©å®šæ€§åˆ†æ•¸
            param_stability = self._calculate_param_stability(all_results, best_params)
            
            logger.info(f"ç¶²æ ¼æœç´¢å®Œæˆï¼Œæ‰¾åˆ°æœ€ä½³åƒæ•¸ï¼š{best_params}")
            logger.info(f"åƒæ•¸ç©©å®šæ€§ï¼š{param_stability}")
            logger.info(f"è¨“ç·´é›†ç¸¾æ•ˆï¼š{best_result['train_metrics']}")
            logger.info(f"äº¤å‰é©—è­‰é›†ç¸¾æ•ˆï¼š{best_result['val_metrics']}")
            logger.info(f"æœ€çµ‚é©—è­‰é›†ç¸¾æ•ˆï¼š{final_validation_metrics}")
            
            return {
                'best_params': best_params,
                'param_stability': param_stability,
                'train_metrics': best_result['train_metrics'],
                'cv_metrics': best_result['val_metrics'],
                'validation_metrics': final_validation_metrics,
                'method': 'Grid Search with Cross-Validation'
            }
        
        logger.warning("ç¶²æ ¼æœç´¢æœªæ‰¾åˆ°æœ‰æ•ˆåƒæ•¸çµ„åˆ")
        return {}
        
    def _validate_param_grid(self, param_grid: Dict) -> None:
        """é©—è­‰åƒæ•¸ç¶²æ ¼çš„æœ‰æ•ˆæ€§"""
        if not param_grid:
            raise ValueError("åƒæ•¸ç¶²æ ¼ä¸èƒ½ç‚ºç©º")
        
        for param_name, param_values in param_grid.items():
            if not param_values:
                raise ValueError(f"åƒæ•¸ {param_name} çš„å€¼åˆ—è¡¨ä¸èƒ½ç‚ºç©º")
            
            # æª¢æŸ¥åƒæ•¸é¡å‹
            if all(isinstance(x, (int, float)) for x in param_values):
                # æ•¸å€¼åƒæ•¸çš„ç¯„åœæª¢æŸ¥
                if min(param_values) <= 0 and param_name.lower() in ['period', 'fast', 'slow', 'signal']:
                    raise ValueError(f"åƒæ•¸ {param_name} çš„å€¼å¿…é ˆå¤§æ–¼0")
                if param_name.lower() in ['std_dev', 'threshold'] and min(param_values) <= 0:
                    raise ValueError(f"åƒæ•¸ {param_name} çš„å€¼å¿…é ˆå¤§æ–¼0")
            
            # æª¢æŸ¥åƒæ•¸æ•¸é‡
            if len(param_values) > 100:
                logger.warning(f"åƒæ•¸ {param_name} çš„å€¼æ•¸é‡éå¤š ({len(param_values)})ï¼Œå¯èƒ½å°è‡´æœç´¢æ™‚é–“éé•·")
    
    def _calculate_param_stability(self, results: List[Dict], best_params: Dict) -> Dict:
        """è¨ˆç®—åƒæ•¸ç©©å®šæ€§åˆ†æ•¸"""
        param_scores = {}
        for param_name in best_params.keys():
            # æ”¶é›†æ‰€æœ‰çµæœä¸­è©²åƒæ•¸çš„å€¼
            param_values = [r['params'][param_name] for r in results]
            # è¨ˆç®—æœ€ä½³å€¼çš„å‡ºç¾é »ç‡
            best_value = best_params[param_name]
            frequency = param_values.count(best_value) / len(param_values)
            # è¨ˆç®—èˆ‡æœ€ä½³å€¼çš„å¹³å‡åå·®
            if isinstance(best_value, (int, float)):
                deviations = [abs(v - best_value) / best_value for v in param_values]
                avg_deviation = np.mean(deviations)
                param_scores[param_name] = {
                    'stability': frequency,
                    'avg_deviation': avg_deviation
                }
            else:
                param_scores[param_name] = {
                    'stability': frequency
                }
        return param_scores

    def _evaluate_random_params(self, args: Tuple[Callable, Dict, pd.DataFrame]) -> Optional[Tuple[Dict, Dict]]:
        """è©•ä¼°å–®å€‹éš¨æ©Ÿæœç´¢åƒæ•¸çµ„åˆ"""
        strategy_class, param_ranges, data = args
        params = {name: random.choice(values) for name, values in param_ranges.items()}
        metrics = self.evaluate_strategy(strategy_class, params, data)
        if metrics and 'sharpe_ratio' in metrics and metrics['trade_count'] > 0:
            return params, metrics
        return None

    def random_search(self, strategy_class, param_grid: Dict, n_iter: int = 100) -> Dict:
        """
        ä½¿ç”¨å¤šé€²ç¨‹é€²è¡Œéš¨æ©Ÿæœç´¢ï¼ŒåŒ…å«äº¤å‰é©—è­‰
        
        Args:
            strategy_class: ç­–ç•¥é¡
            param_grid: åƒæ•¸ç¶²æ ¼ï¼Œæ ¼å¼ç‚º {'param_name': [param_values]}
            n_iter: æ¯æŠ˜çš„è¿­ä»£æ¬¡æ•¸
        """
        # é©—è­‰åƒæ•¸ç¯„åœ
        self._validate_param_grid(param_grid)
        
        logger.info(f"é–‹å§‹éš¨æ©Ÿæœç´¢ï¼Œæ¯æŠ˜è¿­ä»£æ¬¡æ•¸ï¼š{n_iter}")
        
        # æº–å‚™äº¤å‰é©—è­‰
        n_splits = 5  # 5æŠ˜äº¤å‰é©—è­‰
        data_length = len(self.train_data)
        fold_size = data_length // n_splits
        
        all_results = []
        for fold in range(n_splits):
            logger.info(f"é–‹å§‹ç¬¬ {fold + 1} æŠ˜äº¤å‰é©—è­‰")
            
            # æº–å‚™è¨“ç·´å’Œé©—è­‰æ•¸æ“š
            val_start = fold * fold_size
            val_end = val_start + fold_size
            if fold == n_splits - 1:  # æœ€å¾Œä¸€æŠ˜ä½¿ç”¨å‰©é¤˜æ‰€æœ‰æ•¸æ“š
                val_end = data_length
            
            train_data = pd.concat([
                self.train_data.iloc[:val_start],
                self.train_data.iloc[val_end:]
            ])
            val_data = self.train_data.iloc[val_start:val_end]
            
            # æº–å‚™åƒæ•¸çµ„åˆ
            eval_args = [(strategy_class, param_grid, train_data) 
                        for _ in range(n_iter)]
            
            # ä½¿ç”¨å¤šé€²ç¨‹é€²è¡Œè©•ä¼°
            with Pool(processes=self.max_processes) as pool:
                fold_results = list(tqdm(pool.imap(self._evaluate_random_params, eval_args), 
                                      total=n_iter, 
                                      desc=f"ç¬¬ {fold + 1} æŠ˜æœç´¢é€²åº¦"))
            
            # éæ¿¾æœ‰æ•ˆçµæœä¸¦è¨ˆç®—é©—è­‰é›†ç¸¾æ•ˆ
            valid_results = []
            for result in fold_results:
                if result is not None:
                    params, train_metrics = result
                    val_metrics = self.evaluate_strategy(strategy_class, params, val_data)
                    if val_metrics:  # åªä¿ç•™åœ¨é©—è­‰é›†ä¸Šä¹Ÿæœ‰æ•ˆçš„çµæœ
                        valid_results.append({
                            'params': params,
                            'train_metrics': train_metrics,
                            'val_metrics': val_metrics,
                            'fold': fold
                        })
            
            all_results.extend(valid_results)
            
            # æ¸…ç†è¨˜æ†¶é«”
            del train_data, val_data, fold_results, valid_results
            gc.collect()
        
        if all_results:
            # æ ¹æ“šæ‰€æœ‰æŠ˜çš„å¹³å‡ç¸¾æ•ˆé€²è¡Œæ’åº
            def avg_score(result):
                train_sharpe = result['train_metrics']['sharpe_ratio']
                val_sharpe = result['val_metrics']['sharpe_ratio']
                train_sortino = result['train_metrics']['sortino_ratio']
                val_sortino = result['val_metrics']['sortino_ratio']
                train_trades = result['train_metrics']['trade_count']
                val_trades = result['val_metrics']['trade_count']
                
                # ç¶œåˆè€ƒæ…®å¤æ™®æ¯”ç‡ã€ç´¢æè«¾æ¯”ç‡å’Œäº¤æ˜“æ¬¡æ•¸
                train_score = (train_sharpe + train_sortino) * (1 + np.log1p(train_trades) / 10)
                val_score = (val_sharpe + val_sortino) * (1 + np.log1p(val_trades) / 10)
                
                # å¦‚æœä»»ä¸€æŒ‡æ¨™ç‚ºè² ï¼Œå‰‡åˆ†æ•¸ç‚ºè² ç„¡çª®
                if train_sharpe <= 0 or val_sharpe <= 0:
                    return float('-inf')
                
                # è¿”å›è¨“ç·´é›†å’Œé©—è­‰é›†çš„å¹³å‡åˆ†æ•¸
                return (train_score + val_score) / 2
            
            # æ‰¾å‡ºæœ€ä½³åƒæ•¸çµ„åˆ
            best_result = max(all_results, key=avg_score)
            best_params = best_result['params']
            
            # åœ¨å®Œæ•´é©—è­‰é›†ä¸Šé€²è¡Œæœ€çµ‚è©•ä¼°
            final_validation_metrics = self.evaluate_strategy(strategy_class, best_params, self.validation_data)
            
            # è¨ˆç®—åƒæ•¸ç©©å®šæ€§åˆ†æ•¸
            param_stability = self._calculate_param_stability(all_results, best_params)
            
            # è¨ˆç®—åƒæ•¸åˆ†ä½ˆçµ±è¨ˆ
            param_stats = self._calculate_param_distribution(all_results)
            
            logger.info(f"éš¨æ©Ÿæœç´¢å®Œæˆï¼Œæ‰¾åˆ°æœ€ä½³åƒæ•¸ï¼š{best_params}")
            logger.info(f"åƒæ•¸ç©©å®šæ€§ï¼š{param_stability}")
            logger.info(f"åƒæ•¸åˆ†ä½ˆï¼š{param_stats}")
            logger.info(f"è¨“ç·´é›†ç¸¾æ•ˆï¼š{best_result['train_metrics']}")
            logger.info(f"äº¤å‰é©—è­‰é›†ç¸¾æ•ˆï¼š{best_result['val_metrics']}")
            logger.info(f"æœ€çµ‚é©—è­‰é›†ç¸¾æ•ˆï¼š{final_validation_metrics}")
            
            return {
                'best_params': best_params,
                'param_stability': param_stability,
                'param_distribution': param_stats,
                'train_metrics': best_result['train_metrics'],
                'cv_metrics': best_result['val_metrics'],
                'validation_metrics': final_validation_metrics,
                'method': 'Random Search with Cross-Validation'
            }
        
        logger.warning("éš¨æ©Ÿæœç´¢æœªæ‰¾åˆ°æœ‰æ•ˆåƒæ•¸çµ„åˆ")
        return {}
        
    def _calculate_param_distribution(self, results: List[Dict]) -> Dict:
        """è¨ˆç®—åƒæ•¸åˆ†ä½ˆçµ±è¨ˆ"""
        param_stats = {}
        if not results:
            return param_stats
            
        # ç²å–æ‰€æœ‰åƒæ•¸å
        param_names = results[0]['params'].keys()
        
        for param_name in param_names:
            param_values = [r['params'][param_name] for r in results]
            
            if all(isinstance(x, (int, float)) for x in param_values):
                param_stats[param_name] = {
                    'mean': np.mean(param_values),
                    'std': np.std(param_values),
                    'min': min(param_values),
                    'max': max(param_values),
                    'median': np.median(param_values)
                }
            else:
                # å°æ–¼éæ•¸å€¼åƒæ•¸ï¼Œè¨ˆç®—æ¯å€‹å€¼çš„å‡ºç¾é »ç‡
                value_counts = {}
                for value in param_values:
                    value_counts[str(value)] = value_counts.get(str(value), 0) + 1
                param_stats[param_name] = {
                    'value_counts': value_counts
                }
        
        return param_stats

    def brute_force(self, test_func: Callable, param_combinations: List, max_processes: Optional[int] = None) -> List:
        """
        æš´åŠ›æœç´¢æ‰€æœ‰åƒæ•¸çµ„åˆï¼ŒåŒ…å«è¨˜æ†¶é«”ç®¡ç†å’Œé€²åº¦è¿½è¹¤
        
        Args:
            test_func: æ¸¬è©¦å‡½æ•¸
            param_combinations: åƒæ•¸çµ„åˆåˆ—è¡¨
            max_processes: æœ€å¤§é€²ç¨‹æ•¸
        """
        if max_processes is None or max_processes <= 0:
            max_processes = self.max_processes
        
        total_combinations = len(param_combinations)
        logger.info(f"é–‹å§‹æš´åŠ›æœç´¢ï¼Œå…± {total_combinations} çµ„åƒæ•¸çµ„åˆ")
        
        # è¨ˆç®—æ¯æ‰¹æ¬¡çš„å¤§å°ï¼Œé¿å…è¨˜æ†¶é«”æº¢å‡º
        batch_size = min(1000, total_combinations)  # æ¯æ‰¹æ¬¡æœ€å¤š1000çµ„åƒæ•¸
        num_batches = (total_combinations + batch_size - 1) // batch_size
        
        all_results = []
        total_valid = 0
        total_processed = 0
        
        try:
            for batch_idx in range(num_batches):
                start_idx = batch_idx * batch_size
                end_idx = min(start_idx + batch_size, total_combinations)
                current_batch = param_combinations[start_idx:end_idx]
                
                logger.info(f"è™•ç†ç¬¬ {batch_idx + 1}/{num_batches} æ‰¹æ¬¡ï¼Œ"
                          f"åƒæ•¸çµ„åˆ {start_idx + 1} åˆ° {end_idx}")
                
                # ä½¿ç”¨å¤šé€²ç¨‹è™•ç†ç•¶å‰æ‰¹æ¬¡
                with Pool(processes=max_processes) as pool:
                    batch_results = list(tqdm(
                        pool.imap(test_func, current_batch),
                        total=len(current_batch),
                        desc=f"æ‰¹æ¬¡ {batch_idx + 1} é€²åº¦"
                    ))
                
                # éæ¿¾ä¸¦ä¿å­˜æœ‰æ•ˆçµæœ
                valid_results = [r for r in batch_results if r]
                all_results.extend(valid_results)
                
                # æ›´æ–°çµ±è¨ˆä¿¡æ¯
                total_valid += len(valid_results)
                total_processed += len(current_batch)
                
                # è¼¸å‡ºç•¶å‰é€²åº¦
                success_rate = (len(valid_results) / len(current_batch)) * 100
                overall_success_rate = (total_valid / total_processed) * 100
                
                logger.info(f"æ‰¹æ¬¡ {batch_idx + 1} å®Œæˆ:")
                logger.info(f"- ç•¶å‰æ‰¹æ¬¡: è™•ç† {len(current_batch)} çµ„ï¼Œ"
                          f"æœ‰æ•ˆ {len(valid_results)} çµ„ ({success_rate:.2f}%)")
                logger.info(f"- ç¸½é«”é€²åº¦: è™•ç† {total_processed}/{total_combinations} çµ„ï¼Œ"
                          f"æœ‰æ•ˆ {total_valid} çµ„ ({overall_success_rate:.2f}%)")
                
                # æ¸…ç†è¨˜æ†¶é«”
                del batch_results, valid_results
                gc.collect()
                
        except Exception as e:
            logger.error(f"æš´åŠ›æœç´¢éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
            # è¿”å›å·²æ”¶é›†çš„çµæœ
            return all_results
        
        logger.info(f"æš´åŠ›æœç´¢å®Œæˆï¼Œå…±æ‰¾åˆ° {len(all_results)} å€‹æœ‰æ•ˆçµæœ")
        return all_results

    def optimize(self, strategy_class, param_grid: Dict, mode: str = 'grid', n_iter: int = 100, 
                test_func: Optional[Callable] = None, param_combinations: Optional[List] = None, 
                max_processes: Optional[int] = None) -> Dict:
        """
        çµ±ä¸€å„ªåŒ–å…¥å£ï¼ŒåŒ…å«éŒ¯èª¤è™•ç†å’Œè©³ç´°æ—¥èªŒ
        
        Args:
            strategy_class: ç­–ç•¥é¡
            param_grid: åƒæ•¸ç¶²æ ¼
            mode: å„ªåŒ–æ¨¡å¼ ('grid', 'random', 'brute')
            n_iter: éš¨æ©Ÿæœç´¢è¿­ä»£æ¬¡æ•¸
            test_func: æš´åŠ›æœç´¢æ¸¬è©¦å‡½æ•¸
            param_combinations: æš´åŠ›æœç´¢åƒæ•¸çµ„åˆ
            max_processes: æœ€å¤§é€²ç¨‹æ•¸
        """
        start_time = datetime.now()
        logger.info(f"é–‹å§‹å„ªåŒ–ï¼Œæ¨¡å¼ï¼š{mode}")
        logger.info(f"å„ªåŒ–é–‹å§‹æ™‚é–“ï¼š{start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            # é©—è­‰è¼¸å…¥åƒæ•¸
            if not isinstance(param_grid, dict):
                raise ValueError("param_grid å¿…é ˆæ˜¯å­—å…¸é¡å‹")
            
            if mode not in ['grid', 'random', 'brute']:
                raise ValueError(f"ä¸æ”¯æŒçš„å„ªåŒ–æ¨¡å¼ï¼š{mode}")
            
            if mode == 'random' and n_iter <= 0:
                raise ValueError(f"éš¨æ©Ÿæœç´¢çš„è¿­ä»£æ¬¡æ•¸å¿…é ˆå¤§æ–¼0ï¼Œç•¶å‰å€¼ï¼š{n_iter}")
            
            if mode == 'brute':
                if test_func is None:
                    raise ValueError("æš´åŠ›æœç´¢æ¨¡å¼éœ€è¦æä¾› test_func")
                if param_combinations is None:
                    raise ValueError("æš´åŠ›æœç´¢æ¨¡å¼éœ€è¦æä¾› param_combinations")
                if not callable(test_func):
                    raise ValueError("test_func å¿…é ˆæ˜¯å¯èª¿ç”¨çš„å‡½æ•¸")
                if not isinstance(param_combinations, list):
                    raise ValueError("param_combinations å¿…é ˆæ˜¯åˆ—è¡¨é¡å‹")
            
            # è¨˜éŒ„è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
            process = psutil.Process()
            initial_memory = process.memory_info().rss / 1024 / 1024  # MB
            logger.info(f"åˆå§‹è¨˜æ†¶é«”ä½¿ç”¨ï¼š{initial_memory:.2f} MB")
            
            # åŸ·è¡Œå„ªåŒ–
            results = {}
            if mode == 'grid':
                results = self.grid_search(strategy_class, param_grid)
            elif mode == 'random':
                results = self.random_search(strategy_class, param_grid, n_iter)
            elif mode == 'brute' and test_func is not None and param_combinations is not None:
                # åœ¨é€™è£¡æˆ‘å€‘å·²ç¶“ç¢ºä¿äº† test_func å’Œ param_combinations ä¸ç‚º None
                results = {
                    'results': self.brute_force(test_func, param_combinations, max_processes),
                    'method': 'Brute Force'
                }
            
            # æª¢æŸ¥çµæœ
            if not results:
                logger.warning(f"{mode} å„ªåŒ–æœªæ‰¾åˆ°æœ‰æ•ˆçµæœ")
                return {}
            
            # è¨˜éŒ„å„ªåŒ–çµæœæ‘˜è¦
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            final_memory = process.memory_info().rss / 1024 / 1024  # MB
            memory_change = final_memory - initial_memory
            
            summary = {
                'optimization_info': {
                    'mode': mode,
                    'start_time': start_time.strftime('%Y-%m-%d %H:%M:%S'),
                    'end_time': end_time.strftime('%Y-%m-%d %H:%M:%S'),
                    'duration_seconds': duration,
                    'initial_memory_mb': initial_memory,
                    'final_memory_mb': final_memory,
                    'memory_change_mb': memory_change
                }
            }
            
            # åˆä½µå„ªåŒ–çµæœå’Œæ‘˜è¦
            results.update(summary)
            
            # è¼¸å‡ºå„ªåŒ–å®Œæˆä¿¡æ¯
            logger.info(f"å„ªåŒ–å®Œæˆï¼Œè€—æ™‚ï¼š{duration:.2f} ç§’")
            logger.info(f"è¨˜æ†¶é«”ä½¿ç”¨è®ŠåŒ–ï¼š{memory_change:+.2f} MB")
            
            return results
            
        except Exception as e:
            logger.error(f"å„ªåŒ–éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            import traceback
            logger.error(f"éŒ¯èª¤è©³æƒ…:\n{traceback.format_exc()}")
            return {
                'error': str(e),
                'traceback': traceback.format_exc(),
                'optimization_info': {
                    'mode': mode,
                    'start_time': start_time.strftime('%Y-%m-%d %H:%M:%S'),
                    'end_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'status': 'failed'
                }
            }
        finally:
            # å¼·åˆ¶æ¸…ç†è¨˜æ†¶é«”
            gc.collect()

    def create_report(self, results: Dict) -> str:
        """ç”Ÿæˆå„ªåŒ–å ±å‘Š"""
        report = []
        report.append("# ç­–ç•¥å„ªåŒ–å ±å‘Š")
        report.append(f"ç”Ÿæˆæ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        if 'best_params' in results:
            report.append("## æœ€ä½³åƒæ•¸")
            for param, value in results['best_params'].items():
                report.append(f"- {param}: {value}")
            report.append("")
            
            if 'train_metrics' in results:
                report.append("### è¨“ç·´é›†ç¸¾æ•ˆ")
                for metric, value in results['train_metrics'].items():
                    report.append(f"- {metric}: {value:.2f}")
                report.append("")
                
            if 'validation_metrics' in results:
                report.append("### é©—è­‰é›†ç¸¾æ•ˆ")
                for metric, value in results['validation_metrics'].items():
                    report.append(f"- {metric}: {value:.2f}")
                report.append("")
                
        elif 'results' in results:
            report.append("## æš´åŠ›æœç´¢çµæœï¼ˆå‰10åï¼‰")
            for r in results['results'][:10]:
                report.append(str(r))
                
        return "\n".join(report) 